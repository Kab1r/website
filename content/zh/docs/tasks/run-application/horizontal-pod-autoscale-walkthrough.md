---
reviewers:
  - fgrzadkowski
  - jszczepkowski
  - justinsb
  - directxman12
title: Horizontal Pod Autoscaleræ¼”ç»ƒ
content_template: templates/task
weight: 100
---

{{% capture overview %}}

<!--
Horizontal Pod Autoscaler automatically scales the number of pods
in a replication controller, deployment or replica set based on observed CPU utilization
(or, with beta support, on some other, application-provided metrics).
-->

Horizontal Pod Autoscaler å¯ä»¥æ ¹æ® CPU åˆ©ç”¨ç‡è‡ªåŠ¨ä¼¸ç¼© replication
controllerã€deployment æˆ–è€… replica set ä¸­çš„ Pod æ•°é‡ï¼ˆä¹Ÿå¯ä»¥åŸºäºå…¶ä»–åº”ç”¨ç¨‹åºæ
ä¾›çš„åº¦é‡æŒ‡æ ‡ï¼Œç›®å‰è¿™ä¸€åŠŸèƒ½å¤„äº beta ç‰ˆæœ¬ï¼‰ã€‚

<!--
This document walks you through an example of enabling Horizontal Pod Autoscaler for the php-apache server.  For more information on how Horizontal Pod Autoscaler behaves, see the [Horizontal Pod Autoscaler user guide](/docs/tasks/run-application/horizontal-pod-autoscale/).
-->

æœ¬æ–‡å°†å¼•å¯¼æ‚¨äº†è§£å¦‚ä½•ä¸º php-apache æœåŠ¡å™¨é…ç½®å’Œä½¿ç”¨ Horizontal Pod Autoscalerã€‚æ›´
å¤š Horizontal Pod Autoscaler çš„ä¿¡æ¯è¯·å‚é˜…
[Horizontal Pod Autoscaler user guide](/docs/tasks/run-application/horizontal-pod-autoscale/)ã€‚

{{% /capture %}}

{{% capture prerequisites %}}

<!--
This example requires a running Kubernetes cluster and kubectl, version 1.2 or later.
[metrics-server](https://github.com/kubernetes-incubator/metrics-server/) monitoring needs to be deployed in the cluster
to provide metrics via the resource metrics API, as Horizontal Pod Autoscaler uses this API to collect metrics. The instructions for deploying this are on the GitHub repository of [metrics-server](https://github.com/kubernetes-incubator/metrics-server/), if you followed [getting started on GCE guide](/docs/setup/production-environment/turnkey/gce/),
metrics-server monitoring will be turned-on by default.
-->

æœ¬æ–‡ç¤ºä¾‹éœ€è¦ä¸€ä¸ª 1.2 æˆ–è€…æ›´é«˜ç‰ˆæœ¬çš„å¯è¿è¡Œçš„ Kubernetes é›†ç¾¤ä»¥åŠ kubectlã€‚
[metrics-server](https://github.com/kubernetes-incubator/metrics-server/) ä¹Ÿéœ€è¦
éƒ¨ç½²åˆ°é›†ç¾¤ä¸­ï¼Œå®ƒå¯ä»¥é€šè¿‡ resource metrics API å¯¹å¤–æä¾›åº¦é‡æ•°æ®ï¼ŒHorizontal Pod
Autoscaler æ­£æ˜¯æ ¹æ®æ­¤ API æ¥è·å–åº¦é‡æ•°æ®ï¼Œéƒ¨ç½²æ–¹æ³•è¯·å‚è€ƒ
[metrics-server](https://github.com/kubernetes-incubator/metrics-server/) ã€‚å¦‚æœ
ä½ æ­£åœ¨ä½¿ç”¨ GCEï¼ŒæŒ‰ç…§
[getting started on GCE guide](/docs/setup/production-environment/turnkey/gce/)
æ“ä½œï¼Œmetrics-server ä¼šé»˜è®¤å¯åŠ¨ã€‚

<!--
To specify multiple resource metrics for a Horizontal Pod Autoscaler, you must have a Kubernetes cluster
and kubectl at version 1.6 or later.  Furthermore, in order to make use of custom metrics, your cluster
must be able to communicate with the API server providing the custom metrics API. Finally, to use metrics
not related to any Kubernetes object you must have a Kubernetes cluster at version 1.10 or later, and
you must be able to communicate with the API server that provides the external metrics API.
See the [Horizontal Pod Autoscaler user guide](/docs/tasks/run-application/horizontal-pod-autoscale/#support-for-custom-metrics) for more details.
-->

å¦‚æœéœ€è¦ä¸º Horizontal Pod Autoscaler æŒ‡å®šå¤šç§èµ„æºåº¦é‡æŒ‡æ ‡ï¼Œæ‚¨çš„ Kubernetes é›†ç¾¤
ä»¥åŠ kubectl è‡³å°‘éœ€è¦è¾¾åˆ° 1.6 ç‰ˆæœ¬ã€‚ æ­¤å¤–ï¼Œå¦‚æœè¦ä½¿ç”¨è‡ªå®šä¹‰åº¦é‡æŒ‡æ ‡ï¼Œæ‚¨çš„
Kubernetes é›†ç¾¤è¿˜å¿…é¡»èƒ½å¤Ÿä¸æä¾›è¿™äº›è‡ªå®šä¹‰æŒ‡æ ‡çš„ API æœåŠ¡å™¨é€šä¿¡ã€‚æœ€åï¼Œå¦‚æœè¦ä½¿ç”¨
ä¸ Kubernetes å¯¹è±¡æ— å…³çš„åº¦é‡æŒ‡æ ‡ï¼Œåˆ™ Kubernetes é›†ç¾¤ç‰ˆæœ¬è‡³å°‘éœ€è¦è¾¾åˆ° 1.10 ç‰ˆæœ¬ï¼Œ
åŒæ ·ï¼Œéœ€è¦ä¿è¯é›†ç¾¤èƒ½å¤Ÿä¸æä¾›è¿™äº›å¤–éƒ¨æŒ‡æ ‡çš„ API æœåŠ¡å™¨é€šä¿¡ã€‚æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚
é˜…[Horizontal Pod Autoscaler user guide](/docs/tasks/run-application/horizontal-pod-autoscale/#support-for-custom-metrics)ã€‚

{{% /capture %}}

{{% capture steps %}}

<!--
## Run & expose php-apache server
-->

## ç¬¬ä¸€æ­¥ï¼šè¿è¡Œ php-apache æœåŠ¡å™¨å¹¶æš´éœ²æœåŠ¡

<!--
To demonstrate Horizontal Pod Autoscaler we will use a custom docker image based on the php-apache image.
The Dockerfile has the following content:
-->

ä¸ºäº†æ¼”ç¤º Horizontal Pod Autoscalerï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªåŸºäº php-apache é•œåƒçš„å®šåˆ¶
Docker é•œåƒã€‚ Dockerfile å†…å®¹å¦‚ä¸‹ï¼š

```
FROM php:5-apache
ADD index.php /var/www/html/index.php
RUN chmod a+rx index.php
```

<!--
It defines an index.php page which performs some CPU intensive computations:
-->

å®ƒå®šä¹‰ä¸€ä¸ª index.php é¡µé¢æ¥æ‰§è¡Œä¸€äº› CPU å¯†é›†å‹è®¡ç®—ï¼š

```
<?php
  $x = 0.0001;
  for ($i = 0; $i <= 1000000; $i++) {
    $x += sqrt($x);
  }
  echo "OK!";
?>
```

<!--
First, we will start a deployment running the image and expose it as a service:
-->

é¦–å…ˆï¼Œæˆ‘ä»¬å…ˆå¯åŠ¨ä¸€ä¸ª deployment æ¥è¿è¡Œè¿™ä¸ªé•œåƒå¹¶æš´éœ²ä¸€ä¸ªæœåŠ¡:

```shell
kubectl run php-apache --image=k8s.gcr.io/hpa-example --requests=cpu=200m --expose --port=80
```

```
service/php-apache created
deployment.apps/php-apache created
```

<!--
## Create Horizontal Pod Autoscaler
-->

## åˆ›å»º Horizontal Pod Autoscaler

<!--
Now that the server is running, we will create the autoscaler using
[kubectl autoscale](/docs/reference/generated/kubectl/kubectl-commands#autoscale).
The following command will create a Horizontal Pod Autoscaler that maintains between 1 and 10 replicas of the Pods
controlled by the php-apache deployment we created in the first step of these instructions.
Roughly speaking, HPA will increase and decrease the number of replicas
(via the deployment) to maintain an average CPU utilization across all Pods of 50%
(since each pod requests 200 milli-cores by [kubectl run](https://github.com/kubernetes/kubernetes/blob/{{< param "githubbranch" >}}/docs/user-guide/kubectl/kubectl_run.md), this means average CPU usage of 100 milli-cores).
See [here](https://git.k8s.io/community/contributors/design-proposals/autoscaling/horizontal-pod-autoscaler.md#autoscaling-algorithm) for more details on the algorithm.
-->

ç°åœ¨ï¼Œphp-apache æœåŠ¡å™¨å·²ç»è¿è¡Œï¼Œæˆ‘ä»¬å°†é€šè¿‡
[kubectl autoscale](/docs/reference/generated/kubectl/kubectl-commands#autoscale)
å‘½ä»¤åˆ›å»º Horizontal Pod Autoscalerã€‚ ä»¥ä¸‹å‘½ä»¤å°†åˆ›å»ºä¸€ä¸ª Horizontal Pod
Autoscaler ç”¨äºæ§åˆ¶æˆ‘ä»¬ä¸Šä¸€æ­¥éª¤ä¸­åˆ›å»ºçš„ deploymentï¼Œä½¿ Pod çš„å‰¯æœ¬æ•°é‡åœ¨ç»´æŒåœ¨ 1
åˆ° 10 ä¹‹é—´ã€‚å¤§è‡´æ¥è¯´ï¼ŒHPA å°†é€šè¿‡å¢åŠ æˆ–è€…å‡å°‘ Pod å‰¯æœ¬çš„æ•°é‡ï¼ˆé€šè¿‡ Deployment ï¼‰
ä»¥ä¿æŒæ‰€æœ‰ Pod çš„å¹³å‡ CPU åˆ©ç”¨ç‡åœ¨ 50%ä»¥å†…ï¼ˆç”±äºæ¯ä¸ª Pod é€šè¿‡ [kubectl
run](https://github.com/kubernetes/kubernetes/blob/{{< param
"githubbranch" >}}/docs/user-guide/kubectl/kubectl_run.md) ç”³è¯·äº† 200
milli-cores CPUï¼Œæ‰€ä»¥ 50%çš„ CPU åˆ©ç”¨ç‡æ„å‘³ç€å¹³å‡ CPU åˆ©ç”¨ç‡ä¸º 100 milli-coresï¼‰
ã€‚ ç›¸å…³ç®—æ³•çš„è¯¦æƒ…è¯·å‚
é˜…[here](https://git.k8s.io/community/contributors/design-proposals/autoscaling/horizontal-pod-autoscaler.md#autoscaling-algorithm)ã€‚

```shell
kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10
```

```
horizontalpodautoscaler.autoscaling/php-apache autoscaled
```

<!--
We may check the current status of autoscaler by running:
-->

æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹ autoscaler çš„çŠ¶æ€ï¼š

```shell
kubectl get hpa
```

```
NAME         REFERENCE                     TARGET    MINPODS   MAXPODS   REPLICAS   AGE
php-apache   Deployment/php-apache/scale   0% / 50%  1         10        1          18s

```

<!--
Please note that the current CPU consumption is 0% as we are not sending any requests to the server
(the ``CURRENT`` column shows the average across all the pods controlled by the corresponding deployment).
-->

è¯·æ³¨æ„åœ¨ä¸Šé¢çš„å‘½ä»¤è¾“å‡ºä¸­ï¼Œå½“å‰çš„ CPU åˆ©ç”¨ç‡æ˜¯ 0%ï¼Œè¿™æ˜¯ç”±äºæˆ‘ä»¬å°šæœªå‘é€ä»»ä½•è¯·æ±‚åˆ°
æœåŠ¡å™¨ï¼ˆ`CURRENT` åˆ—æ˜¾ç¤ºäº†ç›¸åº” deployment æ‰€æ§åˆ¶çš„æ‰€æœ‰ Pod çš„å¹³å‡ CPU åˆ©ç”¨ç‡ï¼‰ã€‚

<!--
## Increase load
-->

## å¢åŠ è´Ÿè½½

<!--
Now, we will see how the autoscaler reacts to increased load.
We will start a container, and send an infinite loop of queries to the php-apache service (please run it in a different terminal):
-->

ç°åœ¨ï¼Œæˆ‘ä»¬å°†çœ‹åˆ° autoscaler å¦‚ä½•å¯¹å¢åŠ è´Ÿè½½ä½œå‡ºååº”ã€‚ æˆ‘ä»¬å°†å¯åŠ¨ä¸€ä¸ªå®¹å™¨ï¼Œå¹¶é€šè¿‡
ä¸€ä¸ªå¾ªç¯å‘ php-apache æœåŠ¡å™¨å‘é€æ— é™çš„æŸ¥è¯¢è¯·æ±‚ï¼ˆè¯·åœ¨å¦ä¸€ä¸ªç»ˆç«¯ä¸­è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼‰ï¼š

```shell
kubectl run -i --tty load-generator --image=busybox /bin/sh

Hit enter for command prompt

while true; do wget -q -O- http://php-apache; done
```

<!--
Within a minute or so, we should see the higher CPU load by executing:
-->

åœ¨å‡ åˆ†é’Ÿæ—¶é—´å†…ï¼Œé€šè¿‡ä»¥ä¸‹å‘½ä»¤ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ° CPU è´Ÿè½½å‡é«˜äº†ï¼š

```shell
kubectl get hpa
```

```
NAME         REFERENCE                     TARGET      CURRENT   MINPODS   MAXPODS   REPLICAS   AGE
php-apache   Deployment/php-apache/scale   305% / 50%  305%      1         10        1          3m

```

<!--
Here, CPU consumption has increased to 305% of the request.
As a result, the deployment was resized to 7 replicas:
-->

è¿™æ—¶ï¼Œç”±äºè¯·æ±‚å¢å¤šï¼ŒCPU åˆ©ç”¨ç‡å·²ç»å‡è‡³ 305%ã€‚ å¯ä»¥çœ‹åˆ°ï¼Œdeployment çš„å‰¯æœ¬æ•°é‡å·²
ç»å¢é•¿åˆ°äº† 7ï¼š

```shell
kubectl get deployment php-apache
```

```
NAME         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
php-apache   7         7         7            7           19m
```

<!--
{{< note >}}
It may take a few minutes to stabilize the number of replicas. Since the amount
of load is not controlled in any way it may happen that the final number of replicas
will differ from this example.
{{< /note >}}
-->

{{< note >}} æœ‰æ—¶æœ€ç»ˆå‰¯æœ¬çš„æ•°é‡å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ‰èƒ½ç¨³å®šä¸‹æ¥ã€‚ ç”±äºç¯å¢ƒçš„å·®å¼‚ï¼Œä¸åŒ
ç¯å¢ƒä¸­æœ€ç»ˆçš„å‰¯æœ¬æ•°é‡å¯èƒ½ä¸æœ¬ç¤ºä¾‹ä¸­çš„æ•°é‡ä¸åŒã€‚ {{< /note >}}

<!--
## Stop load
-->

## åœæ­¢è´Ÿè½½

<!--
We will finish our example by stopping the user load.

In the terminal where we created the container with `busybox` image, terminate
the load generation by typing `<Ctrl> + C`.

Then we will verify the result state (after a minute or so):
-->

æˆ‘ä»¬å°†é€šè¿‡åœæ­¢è´Ÿè½½æ¥ç»“æŸæˆ‘ä»¬çš„ç¤ºä¾‹ã€‚

åœ¨æˆ‘ä»¬åˆ›å»º busybox å®¹å™¨çš„ç»ˆç«¯ä¸­ï¼Œè¾“å…¥`<Ctrl> + C`æ¥ç»ˆæ­¢è´Ÿè½½çš„äº§ç”Ÿã€‚

ç„¶åæˆ‘ä»¬å¯ä»¥å†æ¬¡æŸ¥çœ‹è´Ÿè½½çŠ¶æ€ï¼ˆç­‰å¾…å‡ åˆ†é’Ÿæ—¶é—´ï¼‰ï¼š

```shell
kubectl get hpa
```

```
NAME         REFERENCE                     TARGET       MINPODS   MAXPODS   REPLICAS   AGE
php-apache   Deployment/php-apache/scale   0% / 50%     1         10        1          11m
```

```shell
kubectl get deployment php-apache
```

```
NAME         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
php-apache   1         1         1            1           27m
```

<!--
Here CPU utilization dropped to 0, and so HPA autoscaled the number of replicas back down to 1.
-->

è¿™æ—¶ï¼ŒCPU åˆ©ç”¨ç‡å·²ç»é™åˆ° 0ï¼Œæ‰€ä»¥ HPA å°†è‡ªåŠ¨ç¼©å‡å‰¯æœ¬æ•°é‡è‡³ 1ã€‚

<!--
{{< note >}}
Autoscaling the replicas may take a few minutes.
{{< /note >}}
-->

{{< note >}} è‡ªåŠ¨ä¼¸ç¼©å®Œæˆå‰¯æœ¬æ•°é‡çš„æ”¹å˜å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿçš„æ—¶é—´ã€‚ {{< /note >}}

{{% /capture %}}

{{% capture discussion %}}

<!--
## Autoscaling on multiple metrics and custom metrics
-->

## åŸºäºå¤šé¡¹åº¦é‡æŒ‡æ ‡å’Œè‡ªå®šä¹‰åº¦é‡æŒ‡æ ‡è‡ªåŠ¨ä¼¸ç¼©

<!--
You can introduce additional metrics to use when autoscaling the `php-apache` Deployment
by making use of the `autoscaling/v2beta2` API version.
-->

åˆ©ç”¨`autoscaling/v2beta2`API ç‰ˆæœ¬ï¼Œæ‚¨å¯ä»¥åœ¨è‡ªåŠ¨ä¼¸ç¼© php-apache è¿™ä¸ª Deployment
æ—¶å¼•å…¥å…¶ä»–åº¦é‡æŒ‡æ ‡ã€‚

<!--
First, get the YAML of your HorizontalPodAutoscaler in the `autoscaling/v2beta2` form:
-->

é¦–å…ˆï¼Œè·å–`autoscaling/v2beta2`æ ¼å¼çš„ HorizontalPodAutoscaler çš„ YAML æ–‡ä»¶ï¼š

```shell
kubectl get hpa.v2beta2.autoscaling -o yaml > /tmp/hpa-v2.yaml
```

<!--
Open the `/tmp/hpa-v2.yaml` file in an editor, and you should see YAML which looks like this:
-->

åœ¨ç¼–è¾‘å™¨ä¸­æ‰“å¼€`/tmp/hpa-v2.yaml`ï¼š

```yaml
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  name: php-apache
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: php-apache
  minReplicas: 1
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 50
status:
  observedGeneration: 1
  lastScaleTime: <some-time>
  currentReplicas: 1
  desiredReplicas: 1
  currentMetrics:
    - type: Resource
      resource:
        name: cpu
        current:
          averageUtilization: 0
          averageValue: 0
```

<!--
Notice that the `targetCPUUtilizationPercentage` field has been replaced with an array called `metrics`.
The CPU utilization metric is a *resource metric*, since it is represented as a percentage of a resource
specified on pod containers.  Notice that you can specify other resource metrics besides CPU.  By default,
the only other supported resource metric is memory.  These resources do not change names from cluster
to cluster, and should always be available, as long as the `metrics.k8s.io` API is available.
-->

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ`targetCPUUtilizationPercentage` å­—æ®µå·²ç»è¢«åä¸º `metrics` çš„æ•°ç»„æ‰€
å–ä»£ã€‚ CPU åˆ©ç”¨ç‡è¿™ä¸ªåº¦é‡æŒ‡æ ‡æ˜¯ä¸€ä¸ª*resource metric*(èµ„æºåº¦é‡æŒ‡æ ‡)ï¼Œå› ä¸ºå®ƒè¡¨ç¤ºå®¹
å™¨ä¸ŠæŒ‡å®šèµ„æºçš„ç™¾åˆ†æ¯”ã€‚é™¤ CPU å¤–ï¼Œæ‚¨è¿˜å¯ä»¥æŒ‡å®šå…¶ä»–èµ„æºåº¦é‡æŒ‡æ ‡ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œç›®å‰
å”¯ä¸€æ”¯æŒçš„å…¶ä»–èµ„æºåº¦é‡æŒ‡æ ‡ä¸ºå†…å­˜ã€‚åªè¦`metrics.k8s.io` API å­˜åœ¨ï¼Œè¿™äº›èµ„æºåº¦é‡æŒ‡
æ ‡å°±æ˜¯å¯ç”¨çš„ï¼Œå¹¶ä¸”ä»–ä»¬ä¸ä¼šåœ¨ä¸åŒçš„ Kubernetes é›†ç¾¤ä¸­æ”¹å˜åç§°ã€‚

<!--
You can also specify resource metrics in terms of direct values, instead of as percentages of the
requested value, by using a `target` type of `AverageValue` instead of `AverageUtilization`, and
setting the corresponding `target.averageValue` field instead of the `target.averageUtilization`.
-->

æ‚¨è¿˜å¯ä»¥æŒ‡å®šèµ„æºåº¦é‡æŒ‡æ ‡ä½¿ç”¨ç»å¯¹æ•°å€¼ï¼Œè€Œä¸æ˜¯ç™¾åˆ†æ¯”ï¼Œä½ éœ€è¦å°†`target`ç±»
å‹`AverageUtilization`æ›¿æ¢æˆ`AverageValue`ï¼ŒåŒæ—¶å°†`target.averageUtilization`æ›¿
æ¢æˆ`target.averageValue`å¹¶è®¾å®šç›¸åº”çš„å€¼ã€‚

<!--
There are two other types of metrics, both of which are considered *custom metrics*: pod metrics and
object metrics.  These metrics may have names which are cluster specific, and require a more
advanced cluster monitoring setup.
-->

è¿˜æœ‰ä¸¤ç§å…¶ä»–ç±»å‹çš„åº¦é‡æŒ‡æ ‡ï¼Œä»–ä»¬è¢«è®¤ä¸ºæ˜¯*custom metrics*ï¼ˆè‡ªå®šä¹‰åº¦é‡æŒ‡æ ‡ï¼‰ï¼šå³
Pod åº¦é‡æŒ‡æ ‡å’Œå¯¹è±¡åº¦é‡æŒ‡æ ‡ï¼ˆpod metrics and object metricsï¼‰ã€‚è¿™äº›åº¦é‡æŒ‡æ ‡å¯èƒ½å…·
æœ‰ç‰¹å®šäºé›†ç¾¤çš„åç§°ï¼Œå¹¶ä¸”éœ€è¦æ›´é«˜çº§çš„é›†ç¾¤ç›‘æ§è®¾ç½®ã€‚

<!--
The first of these alternative metric types is *pod metrics*.  These metrics describe pods, and
are averaged together across pods and compared with a target value to determine the replica count.
They work much like resource metrics, except that they *only* support a `target` type of `AverageValue`.
-->

ç¬¬ä¸€ç§å¯é€‰çš„åº¦é‡æŒ‡æ ‡ç±»å‹æ˜¯ Pod åº¦é‡æŒ‡æ ‡ã€‚è¿™äº›æŒ‡æ ‡ä»æŸä¸€æ–¹é¢æè¿°äº† Podï¼Œåœ¨ä¸åŒ
Pod ä¹‹é—´è¿›è¡Œå¹³å‡ï¼Œå¹¶é€šè¿‡ä¸ä¸€ä¸ªç›®æ ‡å€¼æ¯”å¯¹æ¥ç¡®å®šå‰¯æœ¬çš„æ•°é‡ã€‚å®ƒä»¬çš„å·¥ä½œæ–¹å¼ä¸èµ„æºåº¦
é‡æŒ‡æ ‡éå¸¸ç›¸åƒï¼Œå·®åˆ«æ˜¯å®ƒä»¬ä»…æ”¯æŒ`target` ç±»å‹ä¸º`AverageValue`ã€‚

<!--
Pod metrics are specified using a metric block like this:
-->

Pod åº¦é‡æŒ‡æ ‡é€šè¿‡å¦‚ä¸‹ä»£ç å—å®šä¹‰ï¼š

```yaml
type: Pods
pods:
  metric:
    name: packets-per-second
  target:
    type: AverageValue
    averageValue: 1k
```

<!--
The second alternative metric type is *object metrics*. These metrics describe a different
object in the same namespace, instead of describing pods. The metrics are not necessarily
fetched from the object; they only describe it. Object metrics support `target` types of
both `Value` and `AverageValue`.  With `Value`, the target is compared directly to the returned
metric from the API. With `AverageValue`, the value returned from the custom metrics API is divided
by the number of pods before being compared to the target. The following example is the YAML
representation of the `requests-per-second` metric.
-->

ç¬¬äºŒç§å¯é€‰çš„åº¦é‡æŒ‡æ ‡ç±»å‹æ˜¯å¯¹è±¡åº¦é‡æŒ‡æ ‡ã€‚ç›¸å¯¹äºæè¿° Podï¼Œè¿™äº›åº¦é‡æŒ‡æ ‡ç”¨äºæè¿°ä¸€ä¸ª
åœ¨ç›¸åŒåå­—ç©ºé—´(namespace)ä¸­çš„å…¶ä»–å¯¹è±¡ã€‚è¯·æ³¨æ„è¿™äº›åº¦é‡æŒ‡æ ‡ç”¨äºæè¿°è¿™äº›å¯¹è±¡ï¼Œå¹¶é
ä»å¯¹è±¡ä¸­è·å–ã€‚å¯¹è±¡åº¦é‡æŒ‡æ ‡æ”¯æŒçš„`target`ç±»å‹åŒ…æ‹¬`Value`å’Œ`AverageValue`ã€‚å¦‚æœ
æ˜¯`Value`ç±»å‹ï¼Œtarget å€¼å°†ç›´æ¥ä¸ API è¿”å›çš„åº¦é‡æŒ‡æ ‡æ¯”è¾ƒï¼Œè€Œ`AverageValue`ç±»å‹
ï¼ŒAPI è¿”å›çš„åº¦é‡æŒ‡æ ‡å°†æŒ‰ç…§ Pod æ•°é‡æ‹†åˆ†ï¼Œç„¶åå†ä¸ target å€¼æ¯”è¾ƒã€‚ä¸‹é¢çš„ YAML æ–‡
ä»¶å±•ç¤ºäº†ä¸€ä¸ªè¡¨ç¤º`requests-per-second`çš„åº¦é‡æŒ‡æ ‡ã€‚

```yaml
type: Object
object:
  metric:
    name: requests-per-second
  describedObject:
    apiVersion: networking.k8s.io/v1beta1
    kind: Ingress
    name: main-route
  target:
    type: Value
    value: 2k
```

<!--
If you provide multiple such metric blocks, the HorizontalPodAutoscaler will consider each metric in turn.
The HorizontalPodAutoscaler will calculate proposed replica counts for each metric, and then choose the
one with the highest replica count.
-->

å¦‚æœæ‚¨æŒ‡å®šäº†å¤šä¸ªä¸Šè¿°ç±»å‹çš„åº¦é‡æŒ‡æ ‡ï¼ŒHorizontalPodAutoscaler å°†ä¼šä¾æ¬¡è€ƒé‡å„ä¸ªæŒ‡æ ‡
ã€‚ HorizontalPodAutoscaler å°†ä¼šè®¡ç®—æ¯ä¸€ä¸ªæŒ‡æ ‡æ‰€æè®®çš„å‰¯æœ¬æ•°é‡ï¼Œç„¶åæœ€ç»ˆé€‰æ‹©ä¸€ä¸ª
æœ€é«˜å€¼ã€‚

<!--
For example, if you had your monitoring system collecting metrics about network traffic,
you could update the definition above using `kubectl edit` to look like this:
-->

æ¯”å¦‚ï¼Œå¦‚æœæ‚¨çš„ç›‘æ§ç³»ç»Ÿèƒ½å¤Ÿæä¾›ç½‘ç»œæµé‡æ•°æ®ï¼Œæ‚¨å¯ä»¥é€šè¿‡`kubectl edit`å‘½ä»¤å°†ä¸Šè¿°
Horizontal Pod Autoscaler çš„å®šä¹‰æ›´æ”¹ä¸ºï¼š

```yaml
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: php-apache
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: php-apache
  minReplicas: 1
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: AverageUtilization
          averageUtilization: 50
    - type: Pods
      pods:
        metric:
          name: packets-per-second
        targetAverageValue: 1k
    - type: Object
      object:
        metric:
          name: requests-per-second
        describedObject:
          apiVersion: networking.k8s.io/v1beta1
          kind: Ingress
          name: main-route
        target:
          kind: Value
          value: 10k
status:
  observedGeneration: 1
  lastScaleTime: <some-time>
  currentReplicas: 1
  desiredReplicas: 1
  currentMetrics:
    - type: Resource
      resource:
        name: cpu
      current:
        averageUtilization: 0
        averageValue: 0
    - type: Object
      object:
        metric:
          name: requests-per-second
        describedObject:
          apiVersion: networking.k8s.io/v1beta1
          kind: Ingress
          name: main-route
        current:
          value: 10k
```

<!--
Then, your HorizontalPodAutoscaler would attempt to ensure that each pod was consuming roughly
50% of its requested CPU, serving 1000 packets per second, and that all pods behind the main-route
Ingress were serving a total of 10000 requests per second.
-->

ç„¶åï¼Œæ‚¨çš„ HorizontalPodAutoscaler å°†ä¼šå°è¯•ç¡®ä¿æ¯ä¸ª Pod çš„ CPU åˆ©ç”¨ç‡åœ¨ 50%ä»¥å†…
ï¼Œæ¯ç§’èƒ½å¤ŸæœåŠ¡ 1000 ä¸ªæ•°æ®åŒ…è¯·æ±‚ï¼Œå¹¶ç¡®ä¿æ‰€æœ‰åœ¨ Ingress åçš„ Pod æ¯ç§’èƒ½å¤ŸæœåŠ¡çš„è¯·
æ±‚æ€»æ•°è¾¾åˆ° 10000 ä¸ªã€‚

<!--
### Autoscaling on more specific metrics
-->

### å¤šä¸ªåº¦é‡æŒ‡æ ‡ä¸‹ä¼¸ç¼©

<!--
Many metrics pipelines allow you to describe metrics either by name or by a set of additional
descriptors called _labels_. For all non-resource metric types (pod, object, and external,
described below), you can specify an additional label selector which is passed to your metric
pipeline. For instance, if you collect a metric `http_requests` with the `verb`
label, you can specify the following metric block to scale only on GET requests:
-->

è®¸å¤šåº¦é‡ç®¡é“å…è®¸æ‚¨é€šè¿‡åç§°æˆ–é™„åŠ çš„*labels*æ¥æè¿°åº¦é‡æŒ‡æ ‡ã€‚å¯¹äºæ‰€æœ‰éèµ„æºç±»å‹åº¦é‡
æŒ‡æ ‡(podã€object å’Œåé¢å°†ä»‹ç»çš„ external)ï¼Œï¼Œå¯ä»¥é¢å¤–æŒ‡å®šä¸€ä¸ªæ ‡ç­¾é€‰æ‹©å™¨ã€‚ä¾‹å¦‚ï¼Œ
å¦‚æœä½ å¸Œæœ›æ”¶é›†åŒ…å«`verb`æ ‡ç­¾çš„`http_requests`åº¦é‡æŒ‡æ ‡ï¼Œä½ å¯ä»¥åœ¨ GET è¯·æ±‚ä¸­æŒ‡å®šéœ€
è¦çš„åº¦é‡æŒ‡æ ‡ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```yaml
type: Object
object:
  metric:
    name: `http_requests`
    selector: `verb=GET`
```

<!--
This selector uses the same syntax as the full Kubernetes label selectors. The monitoring pipeline
determines how to collapse multiple series into a single value, if the name and selector
match multiple series. The selector is additive, and cannot select metrics
that describe objects that are **not** the target object (the target pods in the case of the `Pods`
type, and the described object in the case of the `Object` type).
-->

è¿™ä¸ªé€‰æ‹©å™¨ä½¿ç”¨ä¸ Kubernetes æ ‡ç­¾é€‰æ‹©å™¨ç›¸åŒçš„è¯­æ³•ã€‚å¦‚æœåç§°å’Œæ ‡ç­¾é€‰æ‹©å™¨åŒ¹é…åˆ°å¤šä¸ª
ç³»åˆ—ï¼Œç›‘æµ‹ç®¡é“ä¼šå†³å®šå¦‚ä½•å°†å¤šä¸ªç³»åˆ—åˆå¹¶æˆå•ä¸ªå€¼ã€‚é€‰æ‹©å™¨æ˜¯é™„åŠ çš„ï¼Œå®ƒä¸ä¼šé€‰æ‹©ç›®æ ‡ä»¥
å¤–çš„å¯¹è±¡ï¼ˆç±»å‹ä¸º`Pods`çš„ç›®æ ‡å’Œç±»å‹ä¸º`Object`çš„ç›®æ ‡ï¼‰ã€‚

<!--
### Autoscaling on metrics not related to Kubernetes objects
-->

### åŸºäº Kubernetes ä»¥å¤–çš„åº¦é‡æŒ‡æ ‡ä¼¸ç¼©

<!--
Applications running on Kubernetes may need to autoscale based on metrics that don't have an obvious
relationship to any object in the Kubernetes cluster, such as metrics describing a hosted service with
no direct correlation to Kubernetes namespaces. In Kubernetes 1.10 and later, you can address this use case
with *external metrics*.
-->

è¿è¡Œåœ¨ Kubernetes ä¸Šçš„åº”ç”¨ç¨‹åºå¯èƒ½éœ€è¦åŸºäºä¸ Kubernetes é›†ç¾¤ä¸­çš„ä»»ä½•å¯¹è±¡æ²¡æœ‰æ˜æ˜¾
å…³ç³»çš„åº¦é‡æŒ‡æ ‡è¿›è¡Œè‡ªåŠ¨ä¼¸ç¼©ï¼Œä¾‹å¦‚é‚£äº›æè¿°ä¸åœ¨ Kubernetes ä»»ä½• namespaces æœåŠ¡çš„åº¦
é‡æŒ‡æ ‡ã€‚

<!--
Using external metrics requires knowledge of your monitoring system; the setup is
similar to that required when using custom metrics. External metrics allow you to autoscale your cluster
based on any metric available in your monitoring system. Just provide a `metric` block with a
`name` and `selector`, as above, and use the `External` metric type instead of `Object`.
If multiple time series are matched by the `metricSelector`,
the sum of their values is used by the HorizontalPodAutoscaler.
External metrics support both the `Value` and `AverageValue` target types, which function exactly the same
as when you use the `Object` type.
-->

ä½¿ç”¨å¤–éƒ¨çš„åº¦é‡æŒ‡æ ‡ï¼Œéœ€è¦äº†è§£ä½ ä½¿ç”¨çš„ç›‘æ§ç³»ç»Ÿï¼Œç›¸å…³çš„è®¾ç½®ä¸ä½¿ç”¨è‡ªå®šä¹‰è¯•é¢˜æŒ‡æ ‡ç±»ä¼¼
ã€‚ External metrics å¯ä»¥ä½¿ç”¨ä½ çš„ç›‘æ§ç³»ç»Ÿçš„ä»»ä½•æŒ‡æ ‡æ¥è‡ªåŠ¨ä¼¸ç¼©ä½ çš„é›†ç¾¤ã€‚ä½ åªéœ€è¦
åœ¨`metric`å—ä¸­æä¾›`name` å’Œ `selector`ï¼ŒåŒæ—¶å°†ç±»å‹ç”±`Object`æ”¹ä¸º`External`ã€‚å¦‚
æœ`metricSelector`åŒ¹é…åˆ°å¤šä¸ªåº¦é‡æŒ‡æ ‡ï¼ŒHorizontalPodAutoscaler å°†ä¼šæŠŠå®ƒä»¬åŠ å’Œã€‚
External metrics åŒæ—¶æ”¯æŒ`Value`å’Œ`AverageValue`ç±»å‹ï¼Œè¿™ä¸`Object`ç±»å‹çš„åº¦é‡æŒ‡æ ‡
ç›¸åŒã€‚

<!--
For example if your application processes tasks from a hosted queue service, you could add the following
section to your HorizontalPodAutoscaler manifest to specify that you need one worker per 30 outstanding tasks.
-->

ä¾‹å¦‚ï¼Œå¦‚æœä½ çš„åº”ç”¨ç¨‹åºå¤„ç†ä¸»æœºä¸Šçš„æ¶ˆæ¯é˜Ÿåˆ—ï¼Œä¸ºäº†è®©æ¯ 30 ä¸ªä»»åŠ¡æœ‰ 1 ä¸ª workerï¼Œä½
å¯ä»¥å°†ä¸‹é¢çš„å†…å®¹æ·»åŠ åˆ° HorizontalPodAutoscaler çš„é…ç½®ä¸­ã€‚

```yaml
- type: External
  external:
    metric:
      name: queue_messages_ready
      selector: "queue=worker_tasks"
    target:
      type: AverageValue
      averageValue: 30
```

<!--
When possible, it's preferable to use the custom metric target types instead of external metrics, since it's
easier for cluster administrators to secure the custom metrics API.  The external metrics API potentially allows
access to any metric, so cluster administrators should take care when exposing it.
-->

å¦‚æœå¯èƒ½ï¼Œè¿˜æ˜¯æ¨è custom metric è€Œä¸æ˜¯ external metricsï¼Œå› ä¸ºè¿™ä¾¿äºè®©ç³»ç»Ÿç®¡ç†å‘˜
åŠ å›º custom metrics APIã€‚è€Œ external metrics API å¯ä»¥å…è®¸è®¿é—®æ‰€æœ‰çš„åº¦é‡æŒ‡æ ‡ï¼Œå½“
æš´éœ²è¿™äº›æœåŠ¡æ—¶ï¼Œç³»ç»Ÿç®¡ç†å‘˜éœ€è¦ä»”ç»†è€ƒè™‘è¿™ä¸ªé—®é¢˜ã€‚

<!--
## Appendix: Horizontal Pod Autoscaler Status Conditions
-->

## é™„å½•ï¼šHorizontal Pod Autoscaler çŠ¶æ€æ¡ä»¶

<!--
When using the `autoscaling/v2beta2` form of the HorizontalPodAutoscaler, you will be able to see
*status conditions* set by Kubernetes on the HorizontalPodAutoscaler.  These status conditions indicate
whether or not the HorizontalPodAutoscaler is able to scale, and whether or not it is currently restricted
in any way.
-->

å½“ä½¿ç”¨`autoscaling/v2beta2`æ ¼å¼çš„ HorizontalPodAutoscaler æ—¶ï¼Œæ‚¨å°†å¯ä»¥çœ‹åˆ°
Kubernetes ä¸º HorizongtalPodAutoscaler è®¾ç½®çš„çŠ¶æ€æ¡ä»¶ï¼ˆstatus conditionsï¼‰ã€‚è¿™äº›
çŠ¶æ€æ¡ä»¶å¯ä»¥æ˜¾ç¤ºå½“å‰ HorizontalPodAutoscaler æ˜¯å¦èƒ½å¤Ÿæ‰§è¡Œä¼¸ç¼©ä»¥åŠæ˜¯å¦å—åˆ°ä¸€å®šçš„
é™åˆ¶ã€‚

<!--
The conditions appear in the `status.conditions` field.  To see the conditions affecting a HorizontalPodAutoscaler,
we can use `kubectl describe hpa`:
-->

`status.conditions`å­—æ®µå±•ç¤ºäº†è¿™äº›çŠ¶æ€æ¡ä»¶ã€‚å¯ä»¥é€šè¿‡`kubectl describe hpa`å‘½ä»¤æŸ¥
çœ‹å½“å‰å½±å“ HorizontalPodAutoscaler çš„å„ç§çŠ¶æ€æ¡ä»¶ä¿¡æ¯ï¼š

```shell
kubectl describe hpa cm-test
```

```shell
Name:                           cm-test
Namespace:                      prom
Labels:                         <none>
Annotations:                    <none>
CreationTimestamp:              Fri, 16 Jun 2017 18:09:22 +0000
Reference:                      ReplicationController/cm-test
Metrics:                        ( current / target )
  "http_requests" on pods:      66m / 500m
Min replicas:                   1
Max replicas:                   4
ReplicationController pods:     1 current / 1 desired
Conditions:
  Type                  Status  Reason                  Message
  ----                  ------  ------                  -------
  AbleToScale           True    ReadyForNewScale        the last scale time was sufficiently old as to warrant a new scale
  ScalingActive         True    ValidMetricFound        the HPA was able to successfully calculate a replica count from pods metric http_requests
  ScalingLimited        False   DesiredWithinRange      the desired replica count is within the acceptable range
Events:
```

<!--
For this HorizontalPodAutoscaler, we can see several conditions in a healthy state.  The first,
`AbleToScale`, indicates whether or not the HPA is able to fetch and update scales, as well as
whether or not any backoff-related conditions would prevent scaling.  The second, `ScalingActive`,
indicates whether or not the HPA is enabled (i.e. the replica count of the target is not zero) and
is able to calculate desired scales. When it is `False`, it generally indicates problems with
fetching metrics.  Finally, the last condition, `ScalingLimited`, indicates that the desired scale
was capped by the maximum or minimum of the HorizontalPodAutoscaler.  This is an indication that
you may wish to raise or lower the minimum or maximum replica count constraints on your
HorizontalPodAutoscaler.
-->

å¯¹äºä¸Šé¢å±•ç¤ºçš„è¿™ä¸ª HorizontalPodAutoscalerï¼Œæˆ‘ä»¬å¯ä»¥çœ‹å‡ºæœ‰è‹¥å¹²çŠ¶æ€æ¡ä»¶å¤„äºå¥åº·çŠ¶
æ€ã€‚é¦–å…ˆï¼Œ`AbleToScale` è¡¨æ˜ HPA æ˜¯å¦å¯ä»¥è·å–å’Œæ›´æ–°ä¼¸ç¼©ä¿¡æ¯ï¼Œä»¥åŠæ˜¯å¦å­˜åœ¨é˜»æ­¢ä¼¸
ç¼©çš„å„ç§å›é€€æ¡ä»¶ã€‚å…¶æ¬¡ï¼Œ`ScalingActive` è¡¨æ˜ HPA æ˜¯å¦è¢«å¯ç”¨ï¼ˆå³ç›®æ ‡çš„å‰¯æœ¬æ•°é‡ä¸
ä¸ºé›¶ï¼‰ ä»¥åŠæ˜¯å¦èƒ½å¤Ÿå®Œæˆä¼¸ç¼©è®¡ç®—ã€‚å½“è¿™ä¸€çŠ¶æ€ä¸º `False` æ—¶ï¼Œé€šå¸¸è¡¨æ˜è·å–åº¦é‡æŒ‡æ ‡å­˜
åœ¨é—®é¢˜ã€‚æœ€åä¸€ä¸ªæ¡ä»¶ `ScalingLimitted` è¡¨æ˜æ‰€éœ€ä¼¸ç¼©çš„å€¼è¢«
HorizontalPodAutoscaler æ‰€å®šä¹‰çš„æœ€å¤§æˆ–è€…æœ€å°å€¼æ‰€é™åˆ¶ï¼ˆå³å·²ç»è¾¾åˆ°æœ€å¤§æˆ–è€…æœ€å°ä¼¸ç¼©
å€¼ï¼‰ã€‚è¿™é€šå¸¸è¡¨æ˜æ‚¨å¯èƒ½éœ€è¦è°ƒæ•´ HorizontalPodAutoscaler æ‰€å®šä¹‰çš„æœ€å¤§æˆ–è€…æœ€å°å‰¯æœ¬
æ•°é‡çš„é™åˆ¶äº†ã€‚

<!--
## Appendix: Quantities
-->

## é™„å½•ï¼šQuantities

<!--
All metrics in the HorizontalPodAutoscaler and metrics APIs are specified using
a special whole-number notation known in Kubernetes as a *quantity*.  For example,
the quantity `10500m` would be written as `10.5` in decimal notation.  The metrics APIs
will return whole numbers without a suffix when possible, and will generally return
quantities in milli-units otherwise.  This means you might see your metric value fluctuate
between `1` and `1500m`, or `1` and `1.5` when written in decimal notation.  See the
[glossary entry on quantities](/docs/reference/glossary?core-object=true#term-quantity) for more information.
-->

HorizontalPodAutoscaler å’Œ metrics api ä¸­çš„æ‰€æœ‰çš„åº¦é‡æŒ‡æ ‡ä½¿ç”¨ Kubernetes ä¸­ç§°ä¸º
_quantity_ ï¼ˆï¼‰æ®Šæ•´æ•°è¡¨ç¤ºã€‚ä¾‹å¦‚ï¼Œæ•°é‡`10500m`ç”¨åè¿›åˆ¶è¡¨ç¤ºä¸º`10.5`ã€‚å¦‚æœå¯èƒ½çš„è¯
ï¼Œmetrics api å°†è¿”å›æ²¡æœ‰åç¼€çš„æ•´æ•°ï¼Œå¦åˆ™è¿”å›ä»¥åƒåˆ†å•ä½çš„æ•°é‡ã€‚è¿™æ„å‘³ç€æ‚¨å¯èƒ½ä¼šçœ‹
åˆ°æ‚¨çš„åº¦é‡æŒ‡æ ‡åœ¨`1`å’Œ`1500m`ä¹‹é—´æ³¢åŠ¨ï¼Œæˆ–è€…åœ¨åè¿›åˆ¶è®°æ•°æ³•ä¸­çš„`1`å’Œ`1.5`ã€‚æ›´å¤šä¿¡æ¯
ï¼Œè¯·å‚é˜…[åº¦é‡æœ¯è¯­](/docs/reference/glossary?core-object=true#term-quantity)

<!--
## Appendix: Other possible scenarios
-->

## é™„å½•ï¼šå…¶ä»–å¯èƒ½çš„æƒ…å†µ

<!--
### Creating the autoscaler declaratively
-->

### ä½¿ç”¨ YAML æ–‡ä»¶åˆ›å»º autoscaler

<!--
Instead of using `kubectl autoscale` command to create a HorizontalPodAutoscaler imperatively we
can use the following file to create it declaratively:
-->

é™¤äº†ä½¿ç”¨ `kubectl autoscale` å‘½ä»¤ï¼Œä¹Ÿå¯ä»¥æ–‡ä»¶åˆ›å»º HorizontalPodAutoscaler ï¼š

{{< codenew file="application/hpa/php-apache.yaml" >}}

<!--
We will create the autoscaler by executing the following command:
-->

ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤åˆ›å»º autoscalerï¼š

```shell
kubectl create -f https://k8s.io/examples/application/hpa/php-apache.yaml
```

```
horizontalpodautoscaler.autoscaling/php-apache created
```

{{% /capture %}}
