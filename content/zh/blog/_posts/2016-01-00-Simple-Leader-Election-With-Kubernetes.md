## <!--

title: " Simple leader election with Kubernetes and Docker " date: 2016-01-11
slug: simple-leader-election-with-kubernetes

---

#### Overview

-->

title: "Kubernetes å’Œ Docker ç®€å•çš„ leader election" date: 2016-01-11 slug:
simple-leader-election-with-kubernetes url:
/blog/2016/01/Simple-Leader-Election-With-Kubernetes

<!--
Kubernetes simplifies the deployment and operational management of services running on clusters. However, it also simplifies the development of these services. In this post we'll see how you can use Kubernetes to easily perform leader election in your distributed application. Distributed applications usually replicate the tasks of a service for reliability and scalability, but often it is necessary to designate one of the replicas as the leader who is responsible for coordination among all of the replicas.
-->

Kubernetes ç®€åŒ–äº†é›†ç¾¤ä¸Šè¿è¡Œçš„æœåŠ¡çš„éƒ¨ç½²å’Œæ“ä½œç®¡ç†ã€‚ä½†æ˜¯ï¼Œå®ƒä¹Ÿç®€åŒ–äº†è¿™äº›æœåŠ¡çš„å‘
å±•ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•ä½¿ç”¨ Kubernetes åœ¨åˆ†å¸ƒå¼åº”ç”¨ç¨‹åºä¸­è½»æ¾åœ°æ‰§è¡Œ leader
electionã€‚åˆ†å¸ƒå¼åº”ç”¨ç¨‹åºé€šå¸¸ä¸ºäº†å¯é æ€§å’Œå¯ä¼¸ç¼©æ€§è€Œå¤åˆ¶æœåŠ¡çš„ä»»åŠ¡ï¼Œä½†é€šå¸¸éœ€è¦æŒ‡å®š
å…¶ä¸­ä¸€ä¸ªå‰¯æœ¬ä½œä¸ºè´Ÿè´£æ‰€æœ‰å‰¯æœ¬ä¹‹é—´åè°ƒçš„è´Ÿè´£äººã€‚

<!--
Typically in leader election, a set of candidates for becoming leader is identified. These candidates all race to declare themselves the leader. One of the candidates wins and becomes the leader. Once the election is won, the leader continually "heartbeats" to renew their position as the leader, and the other candidates periodically make new attempts to become the leader. This ensures that a new leader is identified quickly, if the current leader fails for some reason.
-->

é€šå¸¸åœ¨ leader election ä¸­ï¼Œä¼šç¡®å®šä¸€ç»„æˆä¸ºé¢†å¯¼è€…çš„å€™é€‰äººã€‚è¿™äº›å€™é€‰äººéƒ½ç«ç›¸å®£å¸ƒè‡ª
å·±ä¸ºé¢†è¢–ã€‚å…¶ä¸­ä¸€ä½å€™é€‰äººè·èƒœå¹¶æˆä¸ºé¢†è¢–ã€‚ä¸€æ—¦é€‰ä¸¾è·èƒœï¼Œé¢†å¯¼è€…å°±ä¼šä¸æ–­åœ°â€œä¿¡å·â€ä»¥è¡¨
ç¤ºä»–ä»¬ä½œä¸ºé¢†å¯¼è€…çš„åœ°ä½ï¼Œå…¶ä»–å€™é€‰äººä¹Ÿä¼šå®šæœŸåœ°åšå‡ºæ–°çš„å°è¯•æ¥æˆä¸ºé¢†å¯¼è€…ã€‚è¿™æ ·å¯ä»¥ç¡®
ä¿åœ¨å½“å‰é¢†å¯¼å› æŸç§åŸå› å¤±è´¥æ—¶ï¼Œå¿«é€Ÿç¡®å®šæ–°é¢†å¯¼ã€‚

<!--
Implementing leader election usually requires either deploying software such as ZooKeeper, etcd or Consul and using it for consensus, or alternately, implementing a consensus algorithm on your own. We will see below that Kubernetes makes the process of using leader election in your application significantly easier.

####  Implementing leader election in Kubernetes
-->

å®ç° leader election é€šå¸¸éœ€è¦éƒ¨ç½² ZooKeeperã€etcd æˆ– Consul ç­‰è½¯ä»¶å¹¶å°†å…¶ç”¨äºåå•†
ä¸€è‡´ï¼Œæˆ–è€…ä¹Ÿå¯ä»¥è‡ªå·±å®ç°åå•†ä¸€è‡´ç®—æ³•ã€‚æˆ‘ä»¬å°†åœ¨ä¸‹é¢çœ‹åˆ°ï¼ŒKubernetes ä½¿åœ¨åº”ç”¨ç¨‹åº
ä¸­ä½¿ç”¨ leader election çš„è¿‡ç¨‹å¤§å¤§ç®€åŒ–ã€‚

####åœ¨ Kubernetes å®æ–½é¢†å¯¼äººé€‰ä¸¾

<!--
The first requirement in leader election is the specification of the set of candidates for becoming the leader. Kubernetes already uses _Endpoints_ to represent a replicated set of pods that comprise a service, so we will re-use this same object. (aside: You might have thought that we would use _ReplicationControllers_, but they are tied to a specific binary, and generally you want to have a single leader even if you are in the process of performing a rolling update)

To perform leader election, we use two properties of all Kubernetes API objects:
-->

Leader election çš„é¦–è¦æ¡ä»¶æ˜¯ç¡®å®šå€™é€‰äººçš„äººé€‰ã€‚Kubernetes å·²ç»ä½¿ç”¨ _Endpoints_ æ¥
è¡¨ç¤ºç»„æˆæœåŠ¡çš„ä¸€ç»„å¤åˆ¶ podï¼Œå› æ­¤æˆ‘ä»¬å°†é‡ç”¨è¿™ä¸ªç›¸åŒçš„å¯¹è±¡ã€‚ï¼ˆæ—ç™½ï¼šæ‚¨å¯èƒ½è®¤ä¸ºæˆ‘ä»¬
ä¼šä½¿ç”¨ _ReplicationControllers_ï¼Œä½†å®ƒä»¬æ˜¯ç»‘å®šåˆ°ç‰¹å®šçš„äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œè€Œä¸”é€šå¸¸æ‚¨å¸Œæœ›
åªæœ‰ä¸€ä¸ªé¢†å¯¼è€…ï¼Œå³ä½¿æ‚¨æ­£åœ¨æ‰§è¡Œæ»šåŠ¨æ›´æ–°ï¼‰

è¦æ‰§è¡Œ leader electionï¼Œæˆ‘ä»¬ä½¿ç”¨æ‰€æœ‰ Kubernetes api å¯¹è±¡çš„ä¸¤ä¸ªå±æ€§ï¼š

<!--
* ResourceVersions - Every API object has a unique ResourceVersion, and you can use these versions to perform compare-and-swap on Kubernetes objects
* Annotations - Every API object can be annotated with arbitrary key/value pairs to be used by clients.

Given these primitives, the code to use master election is relatively straightforward, and you can find it [here][1]. Let's run it ourselves.
-->

- ResourceVersions - æ¯ä¸ª API å¯¹è±¡éƒ½æœ‰ä¸€ä¸ªæƒŸä¸€çš„ ResourceVersionï¼Œæ‚¨å¯ä»¥ä½¿ç”¨è¿™äº›
  ç‰ˆæœ¬å¯¹ Kubernetes å¯¹è±¡æ‰§è¡Œæ¯”è¾ƒå’Œäº¤æ¢
- Annotations - æ¯ä¸ª API å¯¹è±¡éƒ½å¯ä»¥ç”¨å®¢æˆ·ç«¯ä½¿ç”¨çš„ä»»æ„é”®/å€¼å¯¹è¿›è¡Œæ³¨é‡Šã€‚

ç»™å®šè¿™äº›åŸè¯­ï¼Œä½¿ç”¨ master election çš„ä»£ç ç›¸å¯¹ç®€å•ï¼Œæ‚¨å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°[here][1]ã€‚æˆ‘
ä»¬è‡ªå·±æ¥åšå§ã€‚

<!--
```
$ kubectl run leader-elector --image=gcr.io/google_containers/leader-elector:0.4 --replicas=3 -- --election=example
```

This creates a leader election set with 3 replicas:

```
$ kubectl get pods
NAME                   READY     STATUS    RESTARTS   AGE
leader-elector-inmr1   1/1       Running   0          13s
leader-elector-qkq00   1/1       Running   0          13s
leader-elector-sgwcq   1/1       Running   0          13s
```
-->

```
$ kubectl run leader-elector --image=gcr.io/google_containers/leader-elector:0.4 --replicas=3 -- --election=example
```

è¿™å°†åˆ›å»ºä¸€ä¸ªåŒ…å« 3 ä¸ªå‰¯æœ¬çš„ leader election é›†åˆï¼š

```
$ kubectl get pods
NAME                   READY     STATUS    RESTARTS   AGE
leader-elector-inmr1   1/1       Running   0          13s
leader-elector-qkq00   1/1       Running   0          13s
leader-elector-sgwcq   1/1       Running   0          13s
```

<!--
To see which pod was chosen as the leader, you can access the logs of one of the pods, substituting one of your own pod's names in place of

```
${pod_name}, (e.g. leader-elector-inmr1 from the above)

$ kubectl logs -f ${name}
leader is (leader-pod-name)
```
â€¦ Alternately, you can inspect the endpoints object directly:
-->

è¦æŸ¥çœ‹å“ªä¸ª pod è¢«é€‰ä¸ºé¢†å¯¼ï¼Œæ‚¨å¯ä»¥è®¿é—®å…¶ä¸­ä¸€ä¸ª pod çš„æ—¥å¿—ï¼Œç”¨æ‚¨è‡ªå·±çš„ä¸€ä¸ª pod çš„
åç§°æ›¿æ¢

```
${pod_name}, (e.g. leader-elector-inmr1 from the above)

$ kubectl logs -f ${name}
leader is (leader-pod-name)
```

â€¦æˆ–è€…ï¼Œå¯ä»¥ç›´æ¥æ£€æŸ¥ endpoints å¯¹è±¡ï¼š

<!--
_'example' is the name of the candidate set from the above kubectl run â€¦ command_
```
$ kubectl get endpoints example -o yaml
```
Now to validate that leader election actually works, in a different terminal, run:

```
$ kubectl delete pods (leader-pod-name)
```
-->

*'example' æ˜¯ä¸Šé¢ kubectl run â€¦ å‘½ä»¤*ä¸­å€™é€‰é›†çš„åç§°

```
$ kubectl get endpoints example -o yaml
```

ç°åœ¨ï¼Œè¦éªŒè¯ leader election æ˜¯å¦å®é™…æœ‰æ•ˆï¼Œè¯·åœ¨å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œï¼š

```
$ kubectl delete pods (leader-pod-name)
```

<!--
This will delete the existing leader. Because the set of pods is being managed by a replication controller, a new pod replaces the one that was deleted, ensuring that the size of the replicated set is still three. Via leader election one of these three pods is selected as the new leader, and you should see the leader failover to a different pod. Because pods in Kubernetes have a _grace period_ before termination, this may take 30-40 seconds.

The leader-election container provides a simple webserver that can serve on any address (e.g. http://localhost:4040). You can test this out by deleting the existing leader election group and creating a new one where you additionally pass in a --http=(host):(port) specification to the leader-elector image. This causes each member of the set to serve information about the leader via a webhook.
-->

è¿™å°†åˆ é™¤ç°æœ‰é¢†å¯¼ã€‚ç”±äº pod é›†ç”± replication controller ç®¡ç†ï¼Œå› æ­¤æ–°çš„ pod å°†æ›¿æ¢
å·²åˆ é™¤çš„ podï¼Œç¡®ä¿å¤åˆ¶é›†çš„å¤§å°ä»ä¸º 3ã€‚é€šè¿‡ leader electionï¼Œè¿™ä¸‰ä¸ª pod ä¸­çš„ä¸€ä¸ª
è¢«é€‰ä¸ºæ–°çš„é¢†å¯¼è€…ï¼Œæ‚¨åº”è¯¥ä¼šçœ‹åˆ°é¢†å¯¼è€…æ•…éšœè½¬ç§»åˆ°å¦ä¸€ä¸ª podã€‚å› ä¸º Kubernetes çš„åŠèˆ±
åœ¨ç»ˆæ­¢å‰æœ‰ä¸€ä¸ª _grace period_ï¼Œè¿™å¯èƒ½éœ€è¦ 30-40 ç§’ã€‚

Leader-election container æä¾›äº†ä¸€ä¸ªç®€å•çš„ web æœåŠ¡å™¨ï¼Œå¯ä»¥æœåŠ¡äºä»»ä½•åœ°å€(e.g.
http://localhost:4040)ã€‚æ‚¨å¯ä»¥é€šè¿‡åˆ é™¤ç°æœ‰çš„ leader election ç»„å¹¶åˆ›å»ºä¸€ä¸ªæ–°çš„
leader elector ç»„æ¥æµ‹è¯•è¿™ä¸€ç‚¹ï¼Œåœ¨è¯¥ç»„ä¸­ï¼Œæ‚¨è¿˜å¯ä»¥å‘ leader elector æ˜ åƒä¼ é€’
--http=(host):(port) è§„èŒƒã€‚è¿™å°†å¯¼è‡´é›†åˆä¸­çš„æ¯ä¸ªæˆå‘˜é€šè¿‡ webhook æä¾›æœ‰å…³é¢†å¯¼è€…çš„
ä¿¡æ¯ã€‚

<!--
```
# delete the old leader elector group
$ kubectl delete rc leader-elector

# create the new group, note the --http=localhost:4040 flag
$ kubectl run leader-elector --image=gcr.io/google_containers/leader-elector:0.4 --replicas=3 -- --election=example --http=0.0.0.0:4040

# create a proxy to your Kubernetes api server
$ kubectl proxy
```
-->

```
# delete the old leader elector group
$ kubectl delete rc leader-elector

# create the new group, note the --http=localhost:4040 flag
$ kubectl run leader-elector --image=gcr.io/google_containers/leader-elector:0.4 --replicas=3 -- --election=example --http=0.0.0.0:4040

# create a proxy to your Kubernetes api server
$ kubectl proxy
```

<!--
You can then access:


http://localhost:8001/api/v1/proxy/namespaces/default/pods/(leader-pod-name):4040/


And you will see:

```
{"name":"(name-of-leader-here)"}
```
####  Leader election with sidecars
-->

ç„¶åæ‚¨å¯ä»¥è®¿é—®ï¼š

http://localhost:8001/api/v1/proxy/namespaces/default/pods/(leader-pod-name):4040/

ä½ ä¼šçœ‹åˆ°ï¼š

```
{"name":"(name-of-leader-here)"}
```

#### æœ‰å‰¯æ‰‹çš„ leader election

<!--
Ok, that's great, you can do leader election and find out the leader over HTTP, but how can you use it from your own application? This is where the notion of sidecars come in. In Kubernetes, Pods are made up of one or more containers. Often times, this means that you add sidecar containers to your main application to make up a Pod. (for a much more detailed treatment of this subject see my earlier blog post).

The leader-election container can serve as a sidecar that you can use from your own application. Any container in the Pod that's interested in who the current master is can simply access http://localhost:4040 and they'll get back a simple JSON object that contains the name of the current master. Since all containers in a Pod share the same network namespace, there's no service discovery required!
-->

å¥½å§ï¼Œé‚£å¤ªå¥½äº†ï¼Œä½ å¯ä»¥é€šè¿‡ HTTP è¿›è¡Œ leader election å¹¶æ‰¾åˆ° leaderï¼Œä½†æ˜¯ä½ å¦‚ä½•ä»
è‡ªå·±çš„åº”ç”¨ç¨‹åºä¸­ä½¿ç”¨å®ƒå‘¢ï¼Ÿè¿™å°±æ˜¯ sidecar çš„ç”±æ¥ã€‚Kubernetes ä¸­ï¼ŒPods ç”±ä¸€ä¸ªæˆ–å¤š
ä¸ªå®¹å™¨ç»„æˆã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œè¿™æ„å‘³ç€æ‚¨å°† sidecar containers æ·»åŠ åˆ°ä¸»åº”ç”¨ç¨‹åºä¸­ä»¥ç»„æˆ
podã€‚ï¼ˆå…³äºè¿™ä¸ªä¸»é¢˜çš„æ›´è¯¦ç»†çš„å¤„ç†ï¼Œè¯·å‚é˜…æˆ‘ä¹‹å‰çš„åšå®¢æ–‡ç« ï¼‰ã€‚ Leader-election
container å¯ä»¥ä½œä¸ºä¸€ä¸ª sidecarï¼Œæ‚¨å¯ä»¥ä»è‡ªå·±çš„åº”ç”¨ç¨‹åºä¸­ä½¿ç”¨ã€‚Pod ä¸­ä»»ä½•å¯¹å½“å‰
master æ„Ÿå…´è¶£çš„å®¹å™¨éƒ½å¯ä»¥ç®€å•åœ°è®¿é—®http://localhost:4040ï¼Œå®ƒä»¬å°†è¿”å›ä¸€ä¸ªåŒ…å«å½“å‰
master åç§°çš„ç®€å• json å¯¹è±¡ã€‚ç”±äº pod ä¸­ çš„æ‰€æœ‰å®¹å™¨å…±äº«ç›¸åŒçš„ç½‘ç»œå‘½åç©ºé—´ï¼Œå› æ­¤
ä¸éœ€è¦æœåŠ¡å‘ç°ï¼

<!--
For example, here is a simple Node.js application that connects to the leader election sidecar and prints out whether or not it is currently the master. The leader election sidecar sets its identifier to `hostname` by default.

```
var http = require('http');
// This will hold info about the current master
var master = {};

  // The web handler for our nodejs application
  var handleRequest = function(request, response) {
    response.writeHead(200);
    response.end("Master is " + master.name);
  };

  // A callback that is used for our outgoing client requests to the sidecar
  var cb = function(response) {
    var data = '';
    response.on('data', function(piece) { data = data + piece; });
    response.on('end', function() { master = JSON.parse(data); });
  };

  // Make an async request to the sidecar at http://localhost:4040
  var updateMaster = function() {
    var req = http.get({host: 'localhost', path: '/', port: 4040}, cb);
    req.on('error', function(e) { console.log('problem with request: ' + e.message); });
    req.end();
  };

  / / Set up regular updates
  updateMaster();
  setInterval(updateMaster, 5000);

  // set up the web server
  var www = http.createServer(handleRequest);
  www.listen(8080);
  ```
  Of course, you can use this sidecar from any language that you choose that supports HTTP and JSON.
-->

ä¾‹å¦‚ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªç®€å•çš„ Node.js åº”ç”¨ç¨‹åºï¼Œå®ƒè¿æ¥åˆ° leader election sidecar å¹¶æ‰“å°
å‡ºå®ƒå½“å‰æ˜¯å¦æ˜¯ masterã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œleader election sidecar å°†å…¶æ ‡è¯†ç¬¦è®¾ç½®ä¸º
`hostname`ã€‚

```
var http = require('http');
// This will hold info about the current master
var master = {};

  // The web handler for our nodejs application
  var handleRequest = function(request, response) {
    response.writeHead(200);
    response.end("Master is " + master.name);
  };

  // A callback that is used for our outgoing client requests to the sidecar
  var cb = function(response) {
    var data = '';
    response.on('data', function(piece) { data = data + piece; });
    response.on('end', function() { master = JSON.parse(data); });
  };

  // Make an async request to the sidecar at http://localhost:4040
  var updateMaster = function() {
    var req = http.get({host: 'localhost', path: '/', port: 4040}, cb);
    req.on('error', function(e) { console.log('problem with request: ' + e.message); });
    req.end();
  };

  / / Set up regular updates
  updateMaster();
  setInterval(updateMaster, 5000);

  // set up the web server
  var www = http.createServer(handleRequest);
  www.listen(8080);
```

å½“ç„¶ï¼Œæ‚¨å¯ä»¥ä»ä»»ä½•æ”¯æŒ HTTP å’Œ JSON çš„è¯­è¨€ä¸­ä½¿ç”¨è¿™ä¸ª sidecarã€‚

<!--
#### Conclusion


  Hopefully I've shown you how easy it is to build leader election for your distributed application using Kubernetes. In future installments we'll show you how Kubernetes is making building distributed systems even easier. In the meantime, head over to [Google Container Engine][2] or [kubernetes.io][3] to get started with Kubernetes.

  [1]: https://github.com/kubernetes/contrib/pull/353
  [2]: https://cloud.google.com/container-engine/
  [3]: http://kubernetes.io/
-->

#### ç»“è®º

å¸Œæœ›æˆ‘å·²ç»å‘æ‚¨å±•ç¤ºäº†ä½¿ç”¨ Kubernetes ä¸ºæ‚¨çš„åˆ†å¸ƒå¼åº”ç”¨ç¨‹åºæ„å»º leader election æ˜¯
å¤šä¹ˆå®¹æ˜“ã€‚åœ¨ä»¥åçš„éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†å‘æ‚¨å±•ç¤º Kubernetes å¦‚ä½•ä½¿æ„å»ºåˆ†å¸ƒå¼ç³»ç»Ÿå˜å¾—æ›´åŠ
å®¹æ˜“ã€‚åŒæ—¶ï¼Œè½¬åˆ°[Google Container Engine][2]æˆ–[kubernetes.io][3]å¼€å§‹ä½¿ç”¨
Kubernetesã€‚

[1]: https://github.com/kubernetes/contrib/pull/353
[2]: https://cloud.google.com/container-engine/
[3]: http://kubernetes.io/
