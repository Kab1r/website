---
title: Volumes persistants
feature:
  title: Orchestration du stockage
  description: >
    Montez automatiquement le syst√®me de stockage de votre choix, que ce soit √
    partir du stockage local, d'un fournisseur de cloud public tel que <a
    href="https://cloud.google.com/storage/">GCP</a> ou <a
    href="https://aws.amazon.com/products/storage/">AWS</a>, ou un syst√®me de
    stockage r√©seau tel que NFS, iSCSI, Gluster, Ceph, Cinder ou Flocker.

content_template: templates/concept
weight: 20
---

{{% capture overview %}}

Ce document d√©crit l'√©tat actuel de `PersistentVolumes` dans Kubernetes. Une
connaissance des [volumes](/fr/docs/concepts/storage/volumes/) est sugg√©r√©e.

{{% /capture %}}

{{% capture body %}}

## Introduction

La gestion du stockage est un probl√®me distinct de la gestion des instances de
calcul. Le sous-syst√®me `PersistentVolume` fournit une API pour les utilisateurs
et les administrateurs qui abstrait les d√©tails de la fa√ßon dont le stockage est
fourni et de la fa√ßon dont il est utilis√©. Pour ce faire, nous introduisons deux
nouvelles ressources API: `PersistentVolume` et `PersistentVolumeClaim`.

Un `PersistentVolume` (PV) est un √©l√©ment de stockage dans le cluster qui a √©t√©
provisionn√© par un administrateur ou provisionn√© dynamiquement √† l'aide de
[Storage Classes](/docs/concepts/storage/storage-classes/). Il s'agit d'une
ressource dans le cluster, tout comme un n≈ìud est une ressource de cluster. Les
PV sont des plugins de volume comme Volumes, mais ont un cycle de vie
ind√©pendant de tout pod individuel qui utilise le PV. Cet objet API capture les
d√©tails de l'impl√©mentation du stockage, que ce soit NFS, iSCSI ou un syst√®me de
stockage sp√©cifique au fournisseur de cloud.

Un `PersistentVolumeClaim` (PVC) est une demande de stockage par un utilisateur.
Il est similaire √† un Pod. Les pods consomment des ressources de noeud et les
PVC consomment des ressources PV. Les pods peuvent demander des niveaux
sp√©cifiques de ressources (CPU et m√©moire). Les PVC peuvent demander une taille
et des modes d'acc√®s sp√©cifiques (par exemple, ils peuvent √™tre mont√©s une fois
en lecture/√©criture ou plusieurs fois en lecture seule).

Alors que les `PersistentVolumeClaims` permettent √† un utilisateur de consommer
des ressources de stockage abstraites, il est courant que les utilisateurs aient
besoin de `PersistentVolumes` avec des propri√©t√©s et des performances variables
pour diff√©rents probl√®mes. Les administrateurs de cluster doivent √™tre en mesure
d'offrir une vari√©t√© de `PersistentVolumes` qui diff√®rent de bien des fa√ßons
plus que la taille et les modes d'acc√®s, sans exposer les utilisateurs aux
d√©tails de la fa√ßon dont ces volumes sont mis en ≈ìuvre. Pour ces besoins, il
existe la ressource `StorageClass`.

Voir la
[proc√©dure d√©taill√©e avec des exemples](/docs/tasks/configure-pod-container/configure-persistent-volume-storage/).

## Cycle de vie d'un PV et d'un PVC

Les PV sont des ressources du cluster. Les PVC sont des demandes pour ces
ressources et agissent √©galement comme des contr√¥les de r√©clamation pour la
ressource. L'interaction entre les PV et les PVC suit ce cycle de vie:

### Provisionnement

Les PV peuvent √™tre provisionn√©s de deux mani√®res: statiquement ou
dynamiquement.

#### Provisionnement statique

Un administrateur de cluster cr√©e un certain nombre de PV. Ils contiennent les
d√©tails du stockage r√©el, qui est disponible pour une utilisation par les
utilisateurs du cluster. Ils existent dans l'API Kubernetes et sont disponibles
pour la consommation.

#### Provisionnement dynamique

Lorsqu'aucun des PV statiques cr√©√©s par l'administrateur ne correspond au
`PersistentVolumeClaim` d'un utilisateur, le cluster peut essayer de
provisionner dynamiquement un volume sp√©cialement pour le PVC. Ce
provisionnement est bas√© sur les `StorageClasses`: le PVC doit demander une
[storage class](/docs/concepts/storage/storage-classes/) et l'administrateur
doit avoir cr√©√© et configur√© cette classe pour que l'approvisionnement dynamique
se produise. Les PVC qui demandent la classe `""` d√©sactive le provisionnement
dynamique pour eux-m√™mes.

Pour activer le provisionnement de stockage dynamique bas√© sur la classe de
stockage, l'administrateur de cluster doit activer le `DefaultStorageClass` dans
l'[contr√¥leur d'admission](/docs/reference/access-authn-authz/admission-controllers/#defaultstorageclass)
sur le serveur API. Cela peut √™tre fait, par exemple, en veillant √† ce que
`DefaultStorageClass` figure parmi la liste de valeurs s√©par√©es par des virgules
pour l'option `--enable-admission-plugins` du composant serveur API. Pour plus
d'informations sur les options de ligne de commande du serveur API, consultez la
documentation [kube-apiserver](/docs/admin/kube-apiserver/).

### Liaison

Un utilisateur cr√©e, ou dans le cas d'un provisionnement dynamique, a d√©j√† cr√©√©,
un `PersistentVolumeClaim` avec une quantit√© sp√©cifique de stockage demand√©e et
avec certains modes d'acc√®s. Une boucle de contr√¥le dans le ma√Ætre surveille les
nouveaux PVC, trouve un PV correspondant (si possible) et les lie ensemble. Si
un PV a √©t√© dynamiquement provisionn√© pour un nouveau PVC, la boucle liera
toujours ce PV au PVC. Sinon, l'utilisateur obtiendra toujours au moins ce qu'il
a demand√©, mais le volume peut √™tre sup√©rieur √† ce qui a √©t√© demand√©. Une fois
li√©es, les liaisons `PersistentVolumeClaim` sont exclusives, quelle que soit la
fa√ßon dont elles ont √©t√© li√©es. Une liaison PVC-PV est une relation 1-√†-1.

Les PVC resteront non li√©s ind√©finiment s'il n'existe pas de volume
correspondant. Le PVC sera li√© √† mesure que les volumes correspondants
deviendront disponibles. Par exemple, un cluster provisionn√© avec de nombreux PV
50Gi ne correspondrait pas √† un PVC demandant 100Gi. Le PVC peut √™tre li√©
lorsqu'un PV 100Gi est ajout√© au cluster.

### Utilisation

Les Pods utilisent les PVC comme des volumes. Le cluster inspecte le PVC pour
trouver le volume li√© et monte ce volume pour un Pod. Pour les volumes qui
prennent en charge plusieurs modes d'acc√®s, l'utilisateur sp√©cifie le mode
souhait√© lors de l'utilisation de leur PVC comme volume dans un Pod.

Une fois qu'un utilisateur a un PVC et que ce PVC est li√©, le PV li√© appartient
√† l'utilisateur aussi longtemps qu'il en a besoin. Les utilisateurs planifient
des pods et acc√®dent √† leurs PV revendiqu√©s en incluant un
`persistentVolumeClaim` dans le bloc de volumes de leur Pod
[Voir ci-dessous pour les d√©tails de la syntaxe](#claims-as-volumes).

### Protection de l'objet de stockage en cours d'utilisation

Le but de la fonction de protection des objets de stockage utilis√©s est de
garantir que les revendications de volume persistantes (PVC) en cours
d'utilisation par un Pod et les volumes persistants (PV) li√©s aux PVC ne sont
pas supprim√©es du syst√®me, car cela peut entra√Æner des pertes de donn√©es.

{{< note >}} Le PVC est utilis√© activement par un pod lorsqu'il existe un objet
Pod qui utilise le PVC. {{< /note >}}

Si un utilisateur supprime un PVC en cours d'utilisation par un pod, le PVC
n'est pas supprim√© imm√©diatement. L'√©limination du PVC est diff√©r√©e jusqu'√† ce
que le PVC ne soit plus activement utilis√© par les pods. De plus, si un
administrateur supprime un PV li√© √† un PVC, le PV n'est pas supprim√©
imm√©diatement. L'√©limination du PV est diff√©r√©e jusqu'√† ce que le PV ne soit
plus li√© √† un PVC.

Vous pouvez voir qu'un PVC est prot√©g√© lorsque son √©tat est `Terminating` et la
liste `Finalizers` inclus `kubernetes.io/pvc-protection`:

```text
kubectl describe pvc hostpath
Name:          hostpath
Namespace:     default
StorageClass:  example-hostpath
Status:        Terminating
Volume:
Labels:        <none>
Annotations:   volume.beta.kubernetes.io/storage-class=example-hostpath
               volume.beta.kubernetes.io/storage-provisioner=example.com/hostpath
Finalizers:    [kubernetes.io/pvc-protection]
...
```

Vous pouvez voir qu'un PV est prot√©g√© lorsque son √©tat est `Terminating` et la
liste `Finalizers` inclus `kubernetes.io/pv-protection` aussi:

```text
kubectl describe pv task-pv-volume
Name:            task-pv-volume
Labels:          type=local
Annotations:     <none>
Finalizers:      [kubernetes.io/pv-protection]
StorageClass:    standard
Status:          Available
Claim:
Reclaim Policy:  Delete
Access Modes:    RWO
Capacity:        1Gi
Message:
Source:
    Type:          HostPath (bare host directory volume)
    Path:          /tmp/data
    HostPathType:
Events:            <none>
```

### R√©cup√©ration des volumes

Lorsqu'un utilisateur a termin√© avec son volume, il peut supprimer les objets
PVC de l'API qui permet la r√©cup√©ration de la ressource. La politique de
r√©cup√©ration pour un `PersistentVolume` indique au cluster ce qu'il doit faire
du volume une fois qu'il a √©t√© lib√©r√© de son PVC. Actuellement, les volumes
peuvent √™tre conserv√©s, recycl√©s ou supprim√©s.

#### Volumes conserv√©s

La politique de r√©cup√©ration `Retain` permet la r√©cup√©ration manuelle de la
ressource. Lorsque le `PersistentVolumeClaim` est supprim√©, le
`PersistentVolume` existe toujours et le volume est consid√©r√© comme ¬´lib√©r√©¬ª.
Mais il n'est pas encore disponible pour une autre demande car les donn√©es du
demandeur pr√©c√©dent restent sur le volume. Un administrateur peut r√©cup√©rer
manuellement le volume en proc√©dant comme suit.

1. Supprimer le `PersistentVolume`. L'actif de stockage associ√© dans une
   infrastructure externe (comme un volume AWS EBS, GCE PD, Azure Disk ou
   Cinder) existe toujours apr√®s la suppression du PV.
1. Nettoyez manuellement les donn√©es sur l'actif de stockage associ√© en
   cons√©quence.
1. Supprimez manuellement l'actif de stockage associ√© ou, si vous souhaitez
   r√©utiliser le m√™me actif de stockage, cr√©ez un nouveau `PersistentVolume`
   avec la d√©finition de l'actif de stockage.

#### Volumes supprim√©s

Pour les plug-ins de volume qui prennent en charge la strat√©gie de r√©cup√©ration
`Delete`, la suppression supprime √† la fois l'objet `PersistentVolume` de
Kubernetes, ainsi que l'actif de stockage associ√© dans l'infrastructure externe,
tel qu'un volume AWS EBS, GCE PD, Azure Disk ou Cinder. Les volumes qui ont √©t√©
dynamiquement provisionn√©s h√©ritent de la
[politique de r√©cup√©ration de leur `StorageClass`](#politique-de-r√©cup√©ration),
qui par d√©faut est `Delete`. L'administrateur doit configurer la `StorageClass`
selon les attentes des utilisateurs; sinon, le PV doit √™tre √©dit√© ou corrig√©
apr√®s sa cr√©ation. Voir
[Modifier la politique de r√©cup√©ration d'un PersistentVolume](/docs/tasks/administer-cluster/change-pv-reclaim-policy/).

#### Volumes recycl√©s

{{< warning >}} La politique de r√©cup√©ration `Recycle` est obsol√®te. Au lieu de
cela, l'approche recommand√©e consiste √† utiliser l'approvisionnement dynamique.
{{< /warning >}}

Si elle est prise en charge par le plug-in de volume sous-jacent, la strat√©gie
de r√©cup√©ration `Recycle` effectue un nettoyage de base (`rm -rf /thevolume/*`)
sur le volume et le rend √† nouveau disponible pour une nouvelle demande.

Cependant, un administrateur peut configurer un mod√®le de module de recyclage
personnalis√© √† l'aide des arguments de ligne de commande du gestionnaire de
contr√¥leur Kubernetes, comme d√©crit [ici](/docs/admin/kube-controller-manager/).
Le mod√®le de pod de recycleur personnalis√© doit contenir une d√©finition de
`volumes`, comme le montre l'exemple ci-dessous:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pv-recycler
  namespace: default
spec:
  restartPolicy: Never
  volumes:
    - name: vol
      hostPath:
        path: /any/path/it/will/be/replaced
  containers:
    - name: pv-recycler
      image: "k8s.gcr.io/busybox"
      command:
        [
          "/bin/sh",
          "-c",
          'test -e /scrub && rm -rf /scrub/..?* /scrub/.[!.]* /scrub/*  && test
          -z "$(ls -A /scrub)" || exit 1',
        ]
      volumeMounts:
        - name: vol
          mountPath: /scrub
```

Cependant, le chemin particulier sp√©cifi√© dans la partie `volumes` du template
personnalis√© de Pod est remplac√©e par le chemin particulier du volume qui est
recycl√©.

### Redimensionnement des PVC

{{< feature-state for_k8s_version="v1.11" state="beta" >}}

La prise en charge du redimensionnement des PersistentVolumeClaims (PVCs) est
d√©sormais activ√©e par d√©faut. Vous pouvez redimensionner les types de volumes
suivants:

- gcePersistentDisk
- awsElasticBlockStore
- Cinder
- glusterfs
- rbd
- Azure File
- Azure Disk
- Portworx
- FlexVolumes
- CSI

Vous ne pouvez redimensionner un PVC que si le champ `allowVolumeExpansion` de
sa classe de stockage est d√©fini sur true.

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: gluster-vol-default
provisioner: kubernetes.io/glusterfs
parameters:
  resturl: "http://192.168.10.100:8080"
  restuser: ""
  secretNamespace: ""
  secretName: ""
allowVolumeExpansion: true
```

Pour demander un volume plus important pour un PVC, modifiez l'objet PVC et
sp√©cifiez une taille plus grande. Cela d√©clenche l'expansion du volume qui
soutient le `PersistentVolume` sous-jacent. Un nouveau `PersistentVolume` n'est
jamais cr√©√© pour satisfaire la demande. Au lieu de cela, un volume existant est
redimensionn√©.

#### Redimensionnement de volume CSI

{{< feature-state for_k8s_version="v1.16" state="beta" >}}

La prise en charge du redimensionnement des volumes CSI est activ√©e par d√©faut,
mais elle n√©cessite √©galement un pilote CSI sp√©cifique pour prendre en charge le
redimensionnement des volumes. Reportez-vous √† la documentation du pilote CSI
sp√©cifique pour plus d'informations.

#### Redimensionner un volume contenant un syst√®me de fichiers

Vous ne pouvez redimensionner des volumes contenant un syst√®me de fichiers que
si le syst√®me de fichiers est XFS, Ext3 ou Ext4.

Lorsqu'un volume contient un syst√®me de fichiers, le syst√®me de fichiers n'est
redimensionn√© que lorsqu'un nouveau pod utilise le `PersistentVolumeClaim` en
mode ReadWrite. L'extension du syst√®me de fichiers est effectu√©e au d√©marrage
d'un pod ou lorsqu'un pod est en cours d'ex√©cution et que le syst√®me de fichiers
sous-jacent prend en charge le redimensionnement en ligne.

FlexVolumes autorise le redimensionnement si le pilote est d√©fini avec la
capacit√© `requiresFSResize` sur `true`. Le FlexVolume peut √™tre redimensionn√© au
red√©marrage du pod.

#### Redimensionnement d'un PersistentVolumeClaim en cours d'utilisation

{{< feature-state for_k8s_version="v1.15" state="beta" >}}

{{< note >}} Redimensionner un PVCs √† chaud est disponible en version b√™ta
depuis Kubernetes 1.15 et en version alpha depuis 1.11. La fonctionnalit√©
`ExpandInUsePersistentVolumes` doit √™tre activ√©e, ce qui est le cas
automatiquement pour de nombreux clusters de fonctionnalit√©s b√™ta. Se r√©f√©rer √
la documentation de la
[feature gate](/docs/reference/command-line-tools-reference/feature-gates/) pour
plus d'informations. {{< /note >}}

Dans ce cas, vous n'avez pas besoin de supprimer et de recr√©er un pod ou un
d√©ploiement qui utilise un PVC existant. Tout PVC en cours d'utilisation devient
automatiquement disponible pour son pod d√®s que son syst√®me de fichiers a √©t√©
√©tendu. Cette fonctionnalit√© n'a aucun effet sur les PVC qui ne sont pas
utilis√©s par un pod ou un d√©ploiement. Vous devez cr√©er un pod qui utilise le
PVC avant que l'extension puisse se terminer.

Semblable √† d'autres types de volume - les volumes FlexVolume peuvent √©galement
√™tre √©tendus lorsqu'ils sont utilis√©s par un pod.

{{< note >}} Le redimensionnement de FlexVolume n'est possible que lorsque le
pilote sous-jacent prend en charge le redimensionnement. {{< /note >}}

{{< note >}} L'augmentation des volumes EBS est une op√©ration longue. En outre,
il existe un quota par volume d'une modification toutes les 6 heures.
{{< /note >}}

## Types de volumes persistants

Les types `PersistentVolume` sont impl√©ment√©s en tant que plugins. Kubernetes
prend actuellement en charge les plugins suivants:

- GCEPersistentDisk
- AWSElasticBlockStore
- AzureFile
- AzureDisk
- CSI
- FC (Fibre Channel)
- FlexVolume
- Flocker
- NFS
- iSCSI
- RBD (Ceph Block Device)
- CephFS
- Cinder (OpenStack block storage)
- Glusterfs
- VsphereVolume
- Quobyte Volumes
- HostPath (Test de n≈ìud unique uniquement -- le stockage local n'est en aucun
  cas pris en charge et NE FONCTIONNERA PAS dans un cluster √† plusieurs n≈ìuds)
- Portworx Volumes
- ScaleIO Volumes
- StorageOS

## Volumes persistants

Chaque PV contient une sp√©cification et un √©tat, qui sont les sp√©cifications et
l'√©tat du volume.

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv0003
spec:
  capacity:
    storage: 5Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Recycle
  storageClassName: slow
  mountOptions:
    - hard
    - nfsvers=4.1
  nfs:
    path: /tmp
    server: 172.17.0.2
```

{{< note >}} Des logiciels additionnels supportant un type de montage de volume
pourraient √™tre n√©cessaires afin d'utiliser un PersistentVolume depuis un
cluster. Dans l'exemple d'un PersistentVolume de type NFS, le logiciel
additionnel `/sbin/mount.nfs` est requis pour permettre de monter des syst√®mes
de fichiers de type NFS. {{< /note >}}

### Capacit√©

G√©n√©ralement, un PV aura une capacit√© de stockage sp√©cifique. Ceci est r√©gl√© en
utilisant l'attribut `capacity` des PV. Voir le Kubernetes
[mod√®le de ressource](https://git.k8s.io/community/contributors/design-proposals/scheduling/resources.md)
pour comprendre les unit√©s attendues par `capacity`.

Actuellement, la taille du stockage est la seule ressource qui peut √™tre d√©finie
ou demand√©e. Les futurs attributs peuvent inclure les IOPS, le d√©bit, etc.

### Mode volume

{{< feature-state for_k8s_version="v1.13" state="beta" >}}

Avant Kubernetes 1.9, tous les plug-ins de volume cr√©aient un syst√®me de
fichiers sur le volume persistant. Maintenant, vous pouvez d√©finir la valeur de
`volumeMode` sur `block` pour utiliser un p√©riph√©rique de bloc brut, ou
`filesystem` pour utiliser un syst√®me de fichiers. `filesystem` est la valeur
par d√©faut si la valeur est omise. Il s'agit d'un param√®tre API facultatif.

### Modes d'acc√®s

Un `PersistentVolume` peut √™tre mont√© sur un h√¥te de n'importe quelle mani√®re
prise en charge par le fournisseur de ressources. Comme indiqu√© dans le tableau
ci-dessous, les fournisseurs auront des capacit√©s diff√©rentes et les modes
d'acc√®s de chaque PV sont d√©finis sur les modes sp√©cifiques pris en charge par
ce volume particulier. Par exemple, NFS peut prendre en charge plusieurs clients
en lecture/√©criture, mais un PV NFS sp√©cifique peut √™tre export√© sur le serveur
en lecture seule. Chaque PV dispose de son propre ensemble de modes d'acc√®s
d√©crivant les capacit√©s sp√©cifiques de ce PV.

Les modes d'acc√®s sont:

- ReadWriteOnce -- le volume peut √™tre mont√© en lecture-√©criture par un seul
  n≈ìud
- ReadOnlyMany -- le volume peut √™tre mont√© en lecture seule par plusieurs n≈ìuds
- ReadWriteMany -- le volume peut √™tre mont√© en lecture-√©criture par de nombreux
  n≈ìuds

Dans la CLI, les modes d'acc√®s sont abr√©g√©s comme suit:

- RWO - ReadWriteOnce
- ROX - ReadOnlyMany
- RWX - ReadWriteMany

> **Important!** Un volume ne peut √™tre mont√© qu'en utilisant un seul mode
> d'acc√®s √† la fois, m√™me s'il prend en charge plusieurs. Par exemple, un
> GCEPersistentDisk peut √™tre mont√© en tant que ReadWriteOnce par un seul n≈ìud
> ou ReadOnlyMany par plusieurs n≈ìuds, mais pas en m√™me temps.

|        Volume Plugin | ReadWriteOnce    | ReadOnlyMany     | ReadWriteMany                                    |
| -------------------: | :--------------- | :--------------- | :----------------------------------------------- |
| AWSElasticBlockStore | &#x2713;         | -                | -                                                |
|            AzureFile | &#x2713;         | &#x2713;         | &#x2713;                                         |
|            AzureDisk | &#x2713;         | -                | -                                                |
|               CephFS | &#x2713;         | &#x2713;         | &#x2713;                                         |
|               Cinder | &#x2713;         | -                | -                                                |
|                  CSI | d√©pend du pilote | d√©pend du pilote | d√©pend du pilote                                 |
|                   FC | &#x2713;         | &#x2713;         | -                                                |
|           FlexVolume | &#x2713;         | &#x2713;         | d√©pend du pilote                                 |
|              Flocker | &#x2713;         | -                | -                                                |
|    GCEPersistentDisk | &#x2713;         | &#x2713;         | -                                                |
|            Glusterfs | &#x2713;         | &#x2713;         | &#x2713;                                         |
|             HostPath | &#x2713;         | -                | -                                                |
|                iSCSI | &#x2713;         | &#x2713;         | -                                                |
|              Quobyte | &#x2713;         | &#x2713;         | &#x2713;                                         |
|                  NFS | &#x2713;         | &#x2713;         | &#x2713;                                         |
|                  RBD | &#x2713;         | &#x2713;         | -                                                |
|        VsphereVolume | &#x2713;         | -                | - (fonctionne lorsque les pods sont colocalis√©s) |
|       PortworxVolume | &#x2713;         | -                | &#x2713;                                         |
|              ScaleIO | &#x2713;         | &#x2713;         | -                                                |
|            StorageOS | &#x2713;         | -                | -                                                |

### Classe

Un PV peut avoir une classe, qui est sp√©cifi√©e en d√©finissant l'attribut
`storageClassName` sur le nom d'une
[StorageClass](/docs/concepts/storage/storage-classes/). Un PV d'une classe
particuli√®re ne peut √™tre li√© qu'√† des PVC demandant cette classe. Un PV sans
`storageClassName` n'a pas de classe et ne peut √™tre li√© qu'√† des PVC qui ne
demandent aucune classe particuli√®re.

Dans le pass√©, l'annotation `volume.beta.kubernetes.io/storage-class` a √©t√©
utilis√© √† la place de l'attribut `storageClassName`. Cette annotation fonctionne
toujours; cependant, il deviendra compl√®tement obsol√®te dans une future version
de Kubernetes.

### Politique de r√©cupration

Les politiques de r√©cup√©ration actuelles sont:

- Retain -- remise en √©tat manuelle
- Recycle -- effacement de base (`rm -rf /thevolume/*`)
- Delete -- l'√©l√©ment de stockage associ√© tel qu'AWS EBS, GCE PD, Azure Disk ou
  le volume OpenStack Cinder est supprim√©

Actuellement, seuls NFS et HostPath prennent en charge le recyclage. Les volumes
AWS EBS, GCE PD, Azure Disk et Cinder prennent en charge la suppression.

### Options de montage

Un administrateur Kubernetes peut sp√©cifier des options de montage
suppl√©mentaires pour quand un `PersistentVolume` est mont√© sur un n≈ìud.

{{< note >}} Tous les types de volumes persistants ne prennent pas en charge les
options de montage. {{< /note >}}

Les types de volume suivants prennent en charge les options de montage:

- AWSElasticBlockStore
- AzureDisk
- AzureFile
- CephFS
- Cinder (OpenStack block storage)
- GCEPersistentDisk
- Glusterfs
- NFS
- Quobyte Volumes
- RBD (Ceph Block Device)
- StorageOS
- VsphereVolume
- iSCSI

Les options de montage ne sont pas valid√©es, donc le montage √©chouera simplement
si l'une n'est pas valide.

Dans le pass√©, l'annotation `volume.beta.kubernetes.io/mount-options` √©tait
utilis√©e √† la place de l'attribut `mountOptions`. Cette annotation fonctionne
toujours; cependant, elle deviendra compl√®tement obsol√®te dans une future
version de Kubernetes.

### Affinit√© des n≈ìuds

{{< note >}} Pour la plupart des types de volume, vous n'avez pas besoin de
d√©finir ce champ. Il est automatiquement rempli pour les volumes bloc de type
[AWS EBS](/docs/concepts/storage/volumes/#awselasticblockstore),
[GCE PD](/docs/concepts/storage/volumes/#gcepersistentdisk) et
[Azure Disk](/docs/concepts/storage/volumes/#azuredisk). Vous devez d√©finir
explicitement ceci pour les volumes
[locaux](/docs/concepts/storage/volumes/#local). {{< /note >}}

Un PV peut sp√©cifier une [affinit√© de
n≈ìud](/docs/reference/generated/kubernetes-api/{{< param "version" >}}/#volumenodeaffinity-v1-core)
pour d√©finir les contraintes qui limitent les n≈ìuds √† partir desquels ce volume
est accessible. Les pods qui utilisent un PV seront uniquement planifi√©s sur les
n≈ìuds s√©lectionn√©s par l'affinit√© de n≈ìud.

### Phase

Un volume sera dans l'une des phases suivantes:

- Available -- une ressource libre qui n'est pas encore li√©e √† une demande
- Bound -- le volume est li√© √† une demande
- Released -- la demande a √©t√© supprim√©e, mais la ressource n'est pas encore
  r√©cup√©r√©e par le cluster
- Failed -- le volume n'a pas r√©ussi sa r√©cup√©ration automatique

Le CLI affichera le nom du PVC li√© au PV.

## PersistentVolumeClaims

Chaque PVC contient une sp√©cification et un √©tat, qui sont les sp√©cifications et
l'√©tat de la r√©clamation.

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: myclaim
spec:
  accessModes:
    - ReadWriteOnce
  volumeMode: Filesystem
  resources:
    requests:
      storage: 8Gi
  storageClassName: slow
  selector:
    matchLabels:
      release: "stable"
    matchExpressions:
      - { key: environment, operator: In, values: [dev] }
```

### Modes d'acc√®s

Les PVC utilisent les m√™mes conventions que les volumes lorsque vous demandez un
stockage avec des modes d'acc√®s sp√©cifiques.

### Modes de volume

Les PVC utilisent la m√™me convention que les volumes pour indiquer la
consommation du volume en tant que syst√®me de fichiers ou p√©riph√©rique de bloc.

### Ressources

Les PVC, comme les pods, peuvent demander des quantit√©s sp√©cifiques d'une
ressource. Dans ce cas, la demande concerne le stockage. Le m√™me
[mod√®le de ressource](https://git.k8s.io/community/contributors/design-proposals/scheduling/resources.md)
s'applique aux volumes et aux PVC.

### S√©lecteur

Les PVC peuvent sp√©cifier un
[s√©lecteur de labels](/docs/concepts/overview/working-with-objects/labels/#label-selectors)
pour filtrer davantage l'ensemble des volumes. Seuls les volumes dont les
√©tiquettes correspondent au s√©lecteur peuvent √™tre li√©s au PVC. Le s√©lecteur
peut comprendre deux champs:

- `matchLabels` - le volume doit avoir un label avec cette valeur
- `matchExpressions` - une liste des exigences d√©finies en sp√©cifiant la cl√©, la
  liste des valeurs et l'op√©rateur qui relie la cl√© et les valeurs. Les
  op√©rateurs valides incluent In, NotIn, Exists et DoesNotExist.

Toutes les exigences, √† la fois de `matchLabels` et de `matchExpressions`
doivent toutes √™tre satisfaites pour correspondre (application d'un op√©rateur
bool√©en ET).

### Classe

Un PVC peut demander une classe particuli√®re en sp√©cifiant le nom d'une
[StorageClass](/docs/concepts/storage/storage-classes/) en utilisant l'attribut
`storageClassName`. Seuls les PV de la classe demand√©e, ceux ayant le m√™me
`storageClassName` que le PVC, peuvent √™tre li√©s au PVC.

Les PVC n'ont pas n√©cessairement √† demander une classe. Un PVC avec son attribut
`storageClassName` √©gal √† `""` est toujours interpr√©t√© comme demandant un PV
sans classe, il ne peut donc √™tre li√© qu'√† des PV sans classe (pas d'annotation
ou une annotation √©gal √† `""`). Un PVC sans `storageClassName` n'est pas tout √
fait la m√™me et est trait√© diff√©remment par le cluster, selon que le
[`DefaultStorageClass` admission plugin](/docs/reference/access-authn-authz/admission-controllers/#defaultstorageclass)
est activ√©.

- Si le plug-in d'admission est activ√©, l'administrateur peut sp√©cifier une
  valeur par d√©faut `StorageClass`. Tous les PVC qui n'ont pas de
  `storageClassName` ne peuvent √™tre li√©s qu'aux PV de cette valeur par d√©faut.
  La sp√©cification d'une `StorageClass` par d√©faut se fait en d√©finissant
  l'annotation `storageclass.kubernetes.io/is-default-class` √©gal √† `true` dans
  un objet `StorageClass`. Si l'administrateur ne sp√©cifie pas de valeur par
  d√©faut, le cluster r√©pond √† la cr√©ation de PVC comme si le plug-in d'admission
  √©tait d√©sactiv√©. Si plusieurs valeurs par d√©faut sont sp√©cifi√©es, le plugin
  d'admission interdit la cr√©ation de tous les PVC.
- Si le plugin d'admission est d√©sactiv√©, il n'y a aucune notion de d√©faut
  `StorageClass`. Tous les PVC qui n'ont pas `storageClassName` peut √™tre li√©
  uniquement aux PV qui n'ont pas de classe. Dans ce cas, les PVC qui n'ont pas
  `storageClassName` sont trait√©s de la m√™me mani√®re que les PVC qui ont leur
  `storageClassName` √©gal √† `""`.

Selon la m√©thode d'installation, une `StorageClass` par d√©faut peut √™tre
d√©ploy√©e sur un cluster Kubernetes par le gestionnaire d'extensions pendant
l'installation.

Lorsqu'un PVC sp√©cifie un `selector` en plus de demander une `StorageClass`, les
exigences sont ET ensemble: seul un PV de la classe demand√©e et avec les labels
demand√©es peut √™tre li√© au PVC.

{{< note >}} Actuellement, un PVC avec un `selector` non vide ne peut pas avoir
un PV provisionn√© dynamiquement pour cela. {{< /note >}}

Dans le pass√©, l'annotation `volume.beta.kubernetes.io/storage-class` a √©t√©
utilis√© au lieu de l'attribut `storageClassName`. Cette annotation fonctionne
toujours; cependant, elle ne sera pas pris en charge dans une future version de
Kubernetes.

## PVC sous forme de volumes

Les pods acc√®dent au stockage en utilisant le PVC comme volume. Les PVC et les
pods qui les utilisent doivent exister dans le m√™me namespace. Le cluster trouve
le PVC dans le namespace o√π se trouve le pod et l'utilise pour obtenir le
`PersistentVolume` vis√© par le PVC. Le volume est ensuite mont√© sur l'h√¥te et
dans le pod.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  containers:
    - name: myfrontend
      image: nginx
      volumeMounts:
        - mountPath: "/var/www/html"
          name: mypd
  volumes:
    - name: mypd
      persistentVolumeClaim:
        claimName: myclaim
```

### Remarque au sujet des namespaces

Les liaisons `PersistentVolumes` sont exclusives, et comme les objets
`PersistentVolumeClaims` sont des objets vivant dans un namespace donn√©, le
montage de PVC avec les modes "Many" (`ROX`, `RWX`) n'est possible qu'au sein
d'un m√™me namespace.

## Prise en charge du volume de bloc brut

{{< feature-state for_k8s_version="v1.13" state="beta" >}}

Les plug-ins de volume suivants prennent en charge les volumes de blocs bruts, y
compris l'approvisionnement dynamique, le cas √©ch√©ant:

- AWSElasticBlockStore
- AzureDisk
- FC (Fibre Channel)
- GCEPersistentDisk
- iSCSI
- Local volume
- RBD (Ceph Block Device)
- VsphereVolume (alpha)

{{< note >}} Seuls les volumes FC et iSCSI prennent en charge les volumes de
blocs bruts dans Kubernetes 1.9. La prise en charge des plugins suppl√©mentaires
a √©t√© ajout√©e dans 1.10. {{< /note >}}

### Volumes persistants utilisant un volume de bloc brut

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: block-pv
spec:
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  volumeMode: Block
  persistentVolumeReclaimPolicy: Retain
  fc:
    targetWWNs: ["50060e801049cfd1"]
    lun: 0
    readOnly: false
```

### Revendication de volume persistant demandant un volume de bloc brut

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: block-pvc
spec:
  accessModes:
    - ReadWriteOnce
  volumeMode: Block
  resources:
    requests:
      storage: 10Gi
```

### Sp√©cification de pod ajoutant le chemin du p√©riph√©rique de bloc brut dans le conteneur

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-with-block-volume
spec:
  containers:
    - name: fc-container
      image: fedora:26
      command: ["/bin/sh", "-c"]
      args: ["tail -f /dev/null"]
      volumeDevices:
        - name: data
          devicePath: /dev/xvda
  volumes:
    - name: data
      persistentVolumeClaim:
        claimName: block-pvc
```

{{< note >}} Lorsque vous ajoutez un p√©riph√©rique de bloc brut pour un pod, vous
sp√©cifiez le chemin de p√©riph√©rique dans le conteneur au lieu d'un chemin de
montage. {{< /note >}}

### Lier des volumes bloc bruts

Si un utilisateur demande un volume de bloc brut en l'indiquant √† l'aide du
champ `volumeMode` dans la sp√©cification `PersistentVolumeClaim`, les r√®gles de
liaison diff√®rent l√©g√®rement des versions pr√©c√©dentes qui ne consid√©raient pas
ce mode comme faisant partie de la sp√©cification. Voici un tableau des
combinaisons possibles que l'utilisateur et l'administrateur peuvent sp√©cifier
pour demander un p√©riph√©rique de bloc brut. Le tableau indique si le volume sera
li√© ou non compte tenu des combinaisons: Matrice de liaison de volume pour les
volumes provisionn√©s statiquement:

| PV volumeMode | PVC volumeMode |  Result |
| ------------- | :------------- | ------: |
| unspecified   | unspecified    |    BIND |
| unspecified   | Block          | NO BIND |
| unspecified   | Filesystem     |    BIND |
| Block         | unspecified    | NO BIND |
| Block         | Block          |    BIND |
| Block         | Filesystem     | NO BIND |
| Filesystem    | Filesystem     |    BIND |
| Filesystem    | Block          | NO BIND |
| Filesystem    | unspecified    |    BIND |

{{< note >}} Seuls les volumes provisionn√©s statiquement sont pris en charge
pour la version alpha. Les administrateurs doivent prendre en compte ces valeurs
lorsqu'ils travaillent avec des p√©riph√©riques de bloc brut. {{< /note >}}

## Snapshot et restauration de volumes

{{< feature-state for_k8s_version="v1.12" state="alpha" >}}

La fonction de snapshot de volume a √©t√© ajout√©e pour prendre en charge
uniquement les plug-ins de volume CSI. Pour plus de d√©tails, voir
[volume snapshots](/docs/concepts/storage/volume-snapshots/).

Pour activer la prise en charge de la restauration d'un volume √† partir d'un
snapshot de volume, activez la fonctionnalit√© `VolumeSnapshotDataSource` sur
l'apiserver et le controller-manager.

### Cr√©er du PVC √† partir d'un snapshot de volume

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: restore-pvc
spec:
  storageClassName: csi-hostpath-sc
  dataSource:
    name: new-snapshot-test
    kind: VolumeSnapshot
    apiGroup: snapshot.storage.k8s.io
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
```

## Clonage de volume

{{< feature-state for_k8s_version="v1.16" state="beta" >}}

La fonctionnalit√© de clonage de volume a √©t√© ajout√©e pour prendre en charge
uniquement les plug-ins de volume CSI. Pour plus de d√©tails, voir
[clonage de volume](/docs/concepts/storage/volume-pvc-datasource/).

Pour activer la prise en charge du clonage d'un volume √† partir d'une source de
donn√©es PVC, activez la propri√©t√© `VolumePVCDataSource` sur l'apiserver et le
controller-manager.

### Cr√©er un PVC √† partir d'un PVC existant

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: cloned-pvc
spec:
  storageClassName: my-csi-plugin
  dataSource:
    name: existing-src-pvc-name
    kind: PersistentVolumeClaim
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
```

## √âcriture d'une configuration portable

Si vous √©crivez des templates de configuration ou des exemples qui s'ex√©cutent
sur une large gamme de clusters et n√©cessitent un stockage persistant, il est
recommand√© d'utiliser le mod√®le suivant:

- Incluez des objets `PersistentVolumeClaim` dans votre ensemble de config (aux
  c√¥t√©s de `Deployments`, `ConfigMaps`, etc.).
- N'incluez pas d'objets `PersistentVolume` dans la configuration, car
  l'utilisateur qui instancie la configuration peut ne pas √™tre autoris√© √† cr√©er
  des `PersistentVolumes`.
- Donnez √† l'utilisateur la possibilit√© de fournir un nom de classe de stockage
  lors de l'instanciation du template.
  - Si l'utilisateur fournit un nom de classe de stockage, mettez cette valeur
    dans le champ `persistentVolumeClaim.storageClassName`. Cela entra√Ænera le
    PVC pour utiliser la bonne classe de stockage si le cluster a cette
    `StorageClasses` activ√© par l'administrateur.
  - Si l'utilisateur ne fournit pas de nom de classe de stockage, laissez le
    champ `persistentVolumeClaim.storageClassName` √† z√©ro. Cela entra√Ænera un PV
    √† √™tre automatiquement provisionn√© pour l'utilisateur avec la `StorageClass`
    par d√©faut dans le cluster. De nombreux environnements de cluster ont une
    `StorageClass` par d√©faut install√©e, o√π les administrateurs peuvent cr√©er
    leur propre `StorageClass` par d√©faut.
- Dans votre outillage, surveillez les PVCs qui ne sont pas li√©s apr√®s un
  certain temps et signalez-le √† l'utilisateur, car cela peut indiquer que le
  cluster n'a pas de support de stockage dynamique (auquel cas l'utilisateur
  doit cr√©er un PV correspondant) ou que le cluster n'a aucun syst√®me de
  stockage (auquel cas l'utilisateur ne peut pas d√©ployer de configuration
  n√©cessitant des PVCs).

{{% /capture %}}
